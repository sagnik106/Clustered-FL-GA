{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_cluster_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkqZiG_T90QQ"
      },
      "source": [
        "* cluster head\n",
        "* client_ratio\n",
        "* non-IID data\n",
        "* DBSCAN\n",
        "* batch size\n",
        "* plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKvzMMr0a0t6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras import Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams.update({'font.family':'serif'})\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "from itertools import accumulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TeDIUjTbzdC"
      },
      "source": [
        "# Global variablles\n",
        "TOT_CLIENTS = 100\n",
        "learning_rate_list = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
        "NUM_ROUNDS = 10\n",
        "CLIENT_RATIO = 0.3\n",
        "DATA_DIV = 6000\n",
        "NUM_CLIENTS = int(TOT_CLIENTS * CLIENT_RATIO)\n",
        "div_list = [np.random.randint(3000,6000) for i in range(NUM_CLIENTS)]\n",
        "origin_list = [np.random.randint(0,60000-6000) for i in range(NUM_CLIENTS)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI1zQCbjinQN",
        "outputId": "cadec658-d8c0-48e9-d95b-6a931c0483c2"
      },
      "source": [
        "div_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4794,\n",
              " 3137,\n",
              " 3572,\n",
              " 3056,\n",
              " 3391,\n",
              " 3739,\n",
              " 4398,\n",
              " 5397,\n",
              " 3345,\n",
              " 5428,\n",
              " 3048,\n",
              " 5419,\n",
              " 5420,\n",
              " 4330,\n",
              " 3958,\n",
              " 4047,\n",
              " 5289,\n",
              " 4300,\n",
              " 4283,\n",
              " 3209,\n",
              " 4611,\n",
              " 3615,\n",
              " 3009,\n",
              " 3367,\n",
              " 3914,\n",
              " 5253,\n",
              " 5894,\n",
              " 5198,\n",
              " 5897,\n",
              " 4742]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eBpGc2ccKW2",
        "outputId": "cee9b1f6-5cbb-47b1-bb85-3ecd9ba4b1d8"
      },
      "source": [
        "origin_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36308,\n",
              " 31478,\n",
              " 4675,\n",
              " 43813,\n",
              " 22952,\n",
              " 21317,\n",
              " 8091,\n",
              " 39339,\n",
              " 20394,\n",
              " 6151,\n",
              " 39182,\n",
              " 11891,\n",
              " 22790,\n",
              " 14073,\n",
              " 51668,\n",
              " 50561,\n",
              " 50206,\n",
              " 43213,\n",
              " 11,\n",
              " 29651,\n",
              " 22955,\n",
              " 20325,\n",
              " 15303,\n",
              " 51567,\n",
              " 16621,\n",
              " 47746,\n",
              " 32993,\n",
              " 10069,\n",
              " 42597,\n",
              " 14686]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFG9fyvCLNL"
      },
      "source": [
        "# Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuhVjh91qhM8",
        "outputId": "1b61272c-780e-4d80-88ff-2dfa819a25e7"
      },
      "source": [
        "#loading data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape)\n",
        "\n",
        "#reshape\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalixation\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# One Hot encoding\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "y_train=ohe.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test=ohe.transform(y_test.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGYxONSKQxF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a97976a-124a-4afc-b9cd-d75a99768e45"
      },
      "source": [
        "client_train_x = []\n",
        "client_train_y = []\n",
        "\n",
        "for i in range(NUM_CLIENTS):\n",
        "  print([origin_list[i], origin_list[i]+div_list[i]])\n",
        "  client_train_x.append(X_train[origin_list[i]:origin_list[i]+div_list[i]])\n",
        "  client_train_y.append(y_train[origin_list[i]:origin_list[i]+div_list[i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[36308, 41102]\n",
            "[31478, 34615]\n",
            "[4675, 8247]\n",
            "[43813, 46869]\n",
            "[22952, 26343]\n",
            "[21317, 25056]\n",
            "[8091, 12489]\n",
            "[39339, 44736]\n",
            "[20394, 23739]\n",
            "[6151, 11579]\n",
            "[39182, 42230]\n",
            "[11891, 17310]\n",
            "[22790, 28210]\n",
            "[14073, 18403]\n",
            "[51668, 55626]\n",
            "[50561, 54608]\n",
            "[50206, 55495]\n",
            "[43213, 47513]\n",
            "[11, 4294]\n",
            "[29651, 32860]\n",
            "[22955, 27566]\n",
            "[20325, 23940]\n",
            "[15303, 18312]\n",
            "[51567, 54934]\n",
            "[16621, 20535]\n",
            "[47746, 52999]\n",
            "[32993, 38887]\n",
            "[10069, 15267]\n",
            "[42597, 48494]\n",
            "[14686, 19428]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyinh-EjT7za",
        "outputId": "e322df0a-1daf-4098-cebe-9a19cd237044"
      },
      "source": [
        "[i.shape for i in client_train_x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4794, 28, 28, 1),\n",
              " (3137, 28, 28, 1),\n",
              " (3572, 28, 28, 1),\n",
              " (3056, 28, 28, 1),\n",
              " (3391, 28, 28, 1),\n",
              " (3739, 28, 28, 1),\n",
              " (4398, 28, 28, 1),\n",
              " (5397, 28, 28, 1),\n",
              " (3345, 28, 28, 1),\n",
              " (5428, 28, 28, 1),\n",
              " (3048, 28, 28, 1),\n",
              " (5419, 28, 28, 1),\n",
              " (5420, 28, 28, 1),\n",
              " (4330, 28, 28, 1),\n",
              " (3958, 28, 28, 1),\n",
              " (4047, 28, 28, 1),\n",
              " (5289, 28, 28, 1),\n",
              " (4300, 28, 28, 1),\n",
              " (4283, 28, 28, 1),\n",
              " (3209, 28, 28, 1),\n",
              " (4611, 28, 28, 1),\n",
              " (3615, 28, 28, 1),\n",
              " (3009, 28, 28, 1),\n",
              " (3367, 28, 28, 1),\n",
              " (3914, 28, 28, 1),\n",
              " (5253, 28, 28, 1),\n",
              " (5894, 28, 28, 1),\n",
              " (5198, 28, 28, 1),\n",
              " (5897, 28, 28, 1),\n",
              " (4742, 28, 28, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SWQR4QZuGBr",
        "outputId": "01ec2424-420b-4f7a-dd0e-0a071d045536"
      },
      "source": [
        "for num in range(10):\n",
        "  print(div_list[num]*num, div_list[num]*(num+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 4794\n",
            "3137 6274\n",
            "7144 10716\n",
            "9168 12224\n",
            "13564 16955\n",
            "18695 22434\n",
            "26388 30786\n",
            "37779 43176\n",
            "26760 30105\n",
            "48852 54280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8uW5AbJCQcl"
      },
      "source": [
        "# Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "591IbG3Ta9iO"
      },
      "source": [
        "def create_server_model():\n",
        "\n",
        "  model=Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), input_shape = (28,28,1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC9cafnuCTJZ"
      },
      "source": [
        "# Model Cloner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piW-cRlDfKRw"
      },
      "source": [
        "def model_cloner(model, learning_rate, optimizer):\n",
        "    new_model = tf.keras.models.clone_model(model)\n",
        "    new_model.set_weights(model.get_weights())\n",
        "    if optimizer=='adam':\n",
        "        new_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return new_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr4FQwXh40QD"
      },
      "source": [
        "# Initial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUemkC0meg2M"
      },
      "source": [
        "def train_client_initial(num, model, lr_list):\n",
        "  models = []\n",
        "  losses = []\n",
        "\n",
        "  for i in range(len(lr_list)):\n",
        "    models.append(model_cloner(model, lr_list[i], 'adam'))\n",
        "    hist = models[i].fit(client_train_x[num], client_train_y[num], epochs=1, batch_size=32, validation_data=(X_test, y_test))\n",
        "    losses.append(round(hist.history['val_loss'][0], 4))\n",
        "\n",
        "  ind = losses.index(min(losses))\n",
        "\n",
        "  return models[ind], lr_list[ind], losses[ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68OmWpJddDsj",
        "outputId": "268f1a92-f381-49f5-f5f0-d979d64bae60"
      },
      "source": [
        "server_model = create_server_model()\n",
        "server_model.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "server_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               692352    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 693,962\n",
            "Trainable params: 693,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFGyKgX-c0eG",
        "outputId": "9ba5f7f3-273c-45a1-bb27-b519a1ea8607"
      },
      "source": [
        "lr_init = []\n",
        "losses = []\n",
        "data = []\n",
        "client_models = []\n",
        "#start\n",
        "for j in range(NUM_CLIENTS):\n",
        "  print(\"----------------CLIENT \" + str(j) +\"-------------------------\")\n",
        "\n",
        "  lr_list = np.random.choice(learning_rate_list, 3, replace=False)\n",
        "  data.append(train_client_initial(j, server_model, lr_list))\n",
        "\n",
        "  client_models.append(data[j][0])\n",
        "  lr_init.append(data[j][1])\n",
        "  losses.append(data[j][2])\n",
        "\n",
        "#aggregation\n",
        "sum=[i*0 for i in client_models[0].get_weights()]\n",
        "for i in range(NUM_CLIENTS):\n",
        "  sum = [i+j for i, j in zip(client_models[i].get_weights(), sum)]\n",
        "server_model.set_weights([i/NUM_CLIENTS for i in sum])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------CLIENT 0-------------------------\n",
            "150/150 [==============================] - 4s 13ms/step - loss: 0.5018 - accuracy: 0.8517 - val_loss: 0.2854 - val_accuracy: 0.9106\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 10.2626 - accuracy: 0.1141 - val_loss: 2.3047 - val_accuracy: 0.0958\n",
            "150/150 [==============================] - 3s 14ms/step - loss: 2.2921 - accuracy: 0.1585 - val_loss: 2.2836 - val_accuracy: 0.1850\n",
            "----------------CLIENT 1-------------------------\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 36.7502 - accuracy: 0.1865 - val_loss: 2.1347 - val_accuracy: 0.1729\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.6410 - accuracy: 0.8170 - val_loss: 0.3337 - val_accuracy: 0.8968\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 2.2498 - accuracy: 0.3038 - val_loss: 2.1903 - val_accuracy: 0.4336\n",
            "----------------CLIENT 2-------------------------\n",
            "112/112 [==============================] - 2s 18ms/step - loss: 0.5230 - accuracy: 0.8455 - val_loss: 0.4317 - val_accuracy: 0.8805\n",
            "112/112 [==============================] - 2s 14ms/step - loss: 1.5727 - accuracy: 0.6806 - val_loss: 0.9013 - val_accuracy: 0.8350\n",
            "112/112 [==============================] - 2s 18ms/step - loss: 0.6213 - accuracy: 0.8219 - val_loss: 0.3420 - val_accuracy: 0.8945\n",
            "----------------CLIENT 3-------------------------\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 23.6661 - accuracy: 0.1221 - val_loss: 2.3030 - val_accuracy: 0.1135\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.5470 - accuracy: 0.8289 - val_loss: 0.2697 - val_accuracy: 0.9186\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 2.2921 - accuracy: 0.1688 - val_loss: 2.2896 - val_accuracy: 0.1640\n",
            "----------------CLIENT 4-------------------------\n",
            "106/106 [==============================] - 3s 19ms/step - loss: 2.2933 - accuracy: 0.1557 - val_loss: 2.2883 - val_accuracy: 0.1691\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 2.2394 - accuracy: 0.3197 - val_loss: 2.1764 - val_accuracy: 0.4621\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.4955 - accuracy: 0.8464 - val_loss: 0.3304 - val_accuracy: 0.8995\n",
            "----------------CLIENT 5-------------------------\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 1.5464 - accuracy: 0.6799 - val_loss: 0.8788 - val_accuracy: 0.8374\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.6133 - accuracy: 0.8192 - val_loss: 0.3292 - val_accuracy: 0.9055\n",
            "117/117 [==============================] - 2s 14ms/step - loss: 0.4902 - accuracy: 0.8510 - val_loss: 0.3228 - val_accuracy: 0.9088\n",
            "----------------CLIENT 6-------------------------\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 22.2048 - accuracy: 0.1235 - val_loss: 2.3135 - val_accuracy: 0.1010\n",
            "138/138 [==============================] - 3s 15ms/step - loss: 2.2894 - accuracy: 0.1698 - val_loss: 2.2849 - val_accuracy: 0.1807\n",
            "138/138 [==============================] - 3s 15ms/step - loss: 2.2160 - accuracy: 0.3649 - val_loss: 2.1346 - val_accuracy: 0.5140\n",
            "----------------CLIENT 7-------------------------\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 14.1336 - accuracy: 0.1427 - val_loss: 2.2187 - val_accuracy: 0.1536\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 1.3150 - accuracy: 0.7319 - val_loss: 0.6184 - val_accuracy: 0.8735\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 2.2898 - accuracy: 0.1686 - val_loss: 2.2820 - val_accuracy: 0.1890\n",
            "----------------CLIENT 8-------------------------\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 2.2930 - accuracy: 0.1593 - val_loss: 2.2886 - val_accuracy: 0.1679\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.5295 - accuracy: 0.8374 - val_loss: 0.3967 - val_accuracy: 0.8938\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 1.5989 - accuracy: 0.6747 - val_loss: 0.9452 - val_accuracy: 0.8319\n",
            "----------------CLIENT 9-------------------------\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.4425 - accuracy: 0.8683 - val_loss: 0.3692 - val_accuracy: 0.8926\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 11.5014 - accuracy: 0.1758 - val_loss: 2.1135 - val_accuracy: 0.2009\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.4944 - accuracy: 0.8600 - val_loss: 0.3158 - val_accuracy: 0.9084\n",
            "----------------CLIENT 10-------------------------\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.6653 - accuracy: 0.8114 - val_loss: 0.3289 - val_accuracy: 0.9050\n",
            "96/96 [==============================] - 2s 15ms/step - loss: 0.5929 - accuracy: 0.8176 - val_loss: 0.3336 - val_accuracy: 0.9053\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 13.1190 - accuracy: 0.2005 - val_loss: 2.1725 - val_accuracy: 0.1807\n",
            "----------------CLIENT 11-------------------------\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.4446 - accuracy: 0.8583 - val_loss: 0.3517 - val_accuracy: 0.8884\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 2.2093 - accuracy: 0.3691 - val_loss: 2.0979 - val_accuracy: 0.5500\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 8.6747 - accuracy: 0.1148 - val_loss: 2.3076 - val_accuracy: 0.1009\n",
            "----------------CLIENT 12-------------------------\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 2.2037 - accuracy: 0.3832 - val_loss: 2.0907 - val_accuracy: 0.5650\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 2.2907 - accuracy: 0.1664 - val_loss: 2.2815 - val_accuracy: 0.1922\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.4232 - accuracy: 0.8675 - val_loss: 0.3863 - val_accuracy: 0.8889\n",
            "----------------CLIENT 13-------------------------\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.5772 - accuracy: 0.8309 - val_loss: 0.3458 - val_accuracy: 0.8929\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.5139 - accuracy: 0.8457 - val_loss: 0.2941 - val_accuracy: 0.9120\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 1.4911 - accuracy: 0.6848 - val_loss: 0.7548 - val_accuracy: 0.8601\n",
            "----------------CLIENT 14-------------------------\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 1.4941 - accuracy: 0.6870 - val_loss: 0.8001 - val_accuracy: 0.8469\n",
            "124/124 [==============================] - 2s 17ms/step - loss: 0.4920 - accuracy: 0.8535 - val_loss: 0.3156 - val_accuracy: 0.9025\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 2.2276 - accuracy: 0.3413 - val_loss: 2.1517 - val_accuracy: 0.4823\n",
            "----------------CLIENT 15-------------------------\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 13.2290 - accuracy: 0.1653 - val_loss: 2.3011 - val_accuracy: 0.1080\n",
            "127/127 [==============================] - 3s 16ms/step - loss: 1.4835 - accuracy: 0.7022 - val_loss: 0.7884 - val_accuracy: 0.8446\n",
            "127/127 [==============================] - 3s 16ms/step - loss: 2.2271 - accuracy: 0.3462 - val_loss: 2.1503 - val_accuracy: 0.4778\n",
            "----------------CLIENT 16-------------------------\n",
            "166/166 [==============================] - 2s 11ms/step - loss: 0.4653 - accuracy: 0.8616 - val_loss: 0.3199 - val_accuracy: 0.9061\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 2.2887 - accuracy: 0.1753 - val_loss: 2.2816 - val_accuracy: 0.1883\n",
            "166/166 [==============================] - 2s 11ms/step - loss: 0.5317 - accuracy: 0.8493 - val_loss: 0.3185 - val_accuracy: 0.9009\n",
            "----------------CLIENT 17-------------------------\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 2.2895 - accuracy: 0.1726 - val_loss: 2.2853 - val_accuracy: 0.1777\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 10.7899 - accuracy: 0.1391 - val_loss: 2.3107 - val_accuracy: 0.1151\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.5657 - accuracy: 0.8347 - val_loss: 0.3142 - val_accuracy: 0.9118\n",
            "----------------CLIENT 18-------------------------\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 12.1340 - accuracy: 0.1560 - val_loss: 2.2997 - val_accuracy: 0.1074\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.5510 - accuracy: 0.8478 - val_loss: 0.3163 - val_accuracy: 0.9060\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.4691 - accuracy: 0.8632 - val_loss: 0.3245 - val_accuracy: 0.9101\n",
            "----------------CLIENT 19-------------------------\n",
            "101/101 [==============================] - 2s 15ms/step - loss: 0.5472 - accuracy: 0.8345 - val_loss: 0.3436 - val_accuracy: 0.8934\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.7132 - accuracy: 0.7897 - val_loss: 0.3289 - val_accuracy: 0.9073\n",
            "101/101 [==============================] - 3s 20ms/step - loss: 19.0297 - accuracy: 0.1449 - val_loss: 2.2604 - val_accuracy: 0.1331\n",
            "----------------CLIENT 20-------------------------\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 1.4003 - accuracy: 0.7159 - val_loss: 0.7148 - val_accuracy: 0.8556\n",
            "145/145 [==============================] - 2s 12ms/step - loss: 2.2185 - accuracy: 0.3485 - val_loss: 2.1251 - val_accuracy: 0.5391\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.4843 - accuracy: 0.8538 - val_loss: 0.3051 - val_accuracy: 0.9134\n",
            "----------------CLIENT 21-------------------------\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 2.2926 - accuracy: 0.1560 - val_loss: 2.2878 - val_accuracy: 0.1706\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.5959 - accuracy: 0.8271 - val_loss: 0.3316 - val_accuracy: 0.9043\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 2.2342 - accuracy: 0.3320 - val_loss: 2.1677 - val_accuracy: 0.4715\n",
            "----------------CLIENT 22-------------------------\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.6972 - accuracy: 0.8043 - val_loss: 0.3354 - val_accuracy: 0.9054\n",
            "95/95 [==============================] - 2s 20ms/step - loss: 0.5495 - accuracy: 0.8362 - val_loss: 0.3199 - val_accuracy: 0.8974\n",
            "95/95 [==============================] - 2s 16ms/step - loss: 16.8994 - accuracy: 0.1276 - val_loss: 2.3076 - val_accuracy: 0.1135\n",
            "----------------CLIENT 23-------------------------\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 2.2414 - accuracy: 0.3181 - val_loss: 2.1791 - val_accuracy: 0.4512\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 2.2924 - accuracy: 0.1631 - val_loss: 2.2883 - val_accuracy: 0.1692\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.5408 - accuracy: 0.8366 - val_loss: 0.3202 - val_accuracy: 0.9016\n",
            "----------------CLIENT 24-------------------------\n",
            "123/123 [==============================] - 2s 13ms/step - loss: 2.2932 - accuracy: 0.1546 - val_loss: 2.2868 - val_accuracy: 0.1752\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.4860 - accuracy: 0.8544 - val_loss: 0.3599 - val_accuracy: 0.8921\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 2.2346 - accuracy: 0.3242 - val_loss: 2.1594 - val_accuracy: 0.4739\n",
            "----------------CLIENT 25-------------------------\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.5560 - accuracy: 0.8418 - val_loss: 0.2834 - val_accuracy: 0.9122\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 2.2065 - accuracy: 0.3771 - val_loss: 2.0990 - val_accuracy: 0.5402\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 2.2889 - accuracy: 0.1694 - val_loss: 2.2820 - val_accuracy: 0.1902\n",
            "----------------CLIENT 26-------------------------\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 2.1922 - accuracy: 0.4014 - val_loss: 2.0662 - val_accuracy: 0.5960\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.4275 - accuracy: 0.8675 - val_loss: 0.2479 - val_accuracy: 0.9240\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 2.2898 - accuracy: 0.1632 - val_loss: 2.2797 - val_accuracy: 0.1976\n",
            "----------------CLIENT 27-------------------------\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 2.2060 - accuracy: 0.3851 - val_loss: 2.1017 - val_accuracy: 0.5502\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 2.2890 - accuracy: 0.1716 - val_loss: 2.2825 - val_accuracy: 0.1878\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.4654 - accuracy: 0.8599 - val_loss: 0.3290 - val_accuracy: 0.9004\n",
            "----------------CLIENT 28-------------------------\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 1.2429 - accuracy: 0.7468 - val_loss: 0.5765 - val_accuracy: 0.8700\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 14.5230 - accuracy: 0.1275 - val_loss: 2.3062 - val_accuracy: 0.1010\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.4279 - accuracy: 0.8672 - val_loss: 0.2307 - val_accuracy: 0.9331\n",
            "----------------CLIENT 29-------------------------\n",
            "149/149 [==============================] - 3s 12ms/step - loss: 1.4081 - accuracy: 0.7115 - val_loss: 0.6867 - val_accuracy: 0.8690\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.5549 - accuracy: 0.8349 - val_loss: 0.2916 - val_accuracy: 0.9139\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.4930 - accuracy: 0.8536 - val_loss: 0.4048 - val_accuracy: 0.8951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PB6ZV6dDWsu",
        "outputId": "000e2827-99aa-498e-e68e-8f750317054d"
      },
      "source": [
        "server_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4568 - accuracy: 0.9178\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.456783652305603, 0.9178000092506409]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKNPHQV5Aj1"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI01x0RMlj9r",
        "outputId": "c2d38f45-4483-4836-a8b0-d18e1df27090"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "#lr_init = [0.01, 0.1, 0.00001, 0.001, 0.001, 0.0001, 0.1, 0.001, 0.00001, 0.000001]\n",
        "lr_init1 = np.reshape(lr_init, (-1,1))\n",
        "#print(lr_init)\n",
        "\n",
        "model = DBSCAN(eps=0.0001, min_samples=2)\n",
        "yhat = model.fit_predict(lr_init1)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 0 0 0 2 2 0 1 1 0 0 0 0 2 1 1 1 1 0 1 0 0 0 1 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRe2H2yw5E-4"
      },
      "source": [
        "# Genetic Mutation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQaytgH0m14"
      },
      "source": [
        "def mutate(lr):\n",
        "\n",
        "    num = random.randint(-1,1)\n",
        "    lr += (lr/10)*num\n",
        "\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5XwnJgL5HYC"
      },
      "source": [
        "# Genetic Mating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqZ5ySE815Ku"
      },
      "source": [
        "def crossover(lrs):\n",
        "  new_lrs = []\n",
        "\n",
        "  new_lrs.append(lrs[0])\n",
        "  if(len(lrs) >1):\n",
        "    new_lrs.append(lrs[1])\n",
        "\n",
        "  if(len(lrs) > 2):\n",
        "    for i in range(2, len(lrs)):\n",
        "      parentA = random.randint(0, len(lrs)-1)\n",
        "      parentB = random.randint(0, len(lrs)-1)\n",
        "\n",
        "      new_lrs.append(mutate((lrs[parentA]+lrs[parentB])/2))\n",
        "\n",
        "  return new_lrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26iigDPI5KwA"
      },
      "source": [
        "# Genetic Evolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALDdAywv0nHM"
      },
      "source": [
        "def evolve(losses, lrs):\n",
        "    sorted_y_idx_list = sorted(range(len(losses)),key=lambda x:losses[x])\n",
        "    lrs = [lrs[i] for i in sorted_y_idx_list]\n",
        "    lrs = crossover(lrs)\n",
        "\n",
        "    return lrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK_QwKuA5PIv"
      },
      "source": [
        "# Edge Device training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy5wHd3GX0i-"
      },
      "source": [
        "def train_client(num, model, lr):\n",
        "\n",
        "  new_model = model_cloner(model, lr, 'adam')\n",
        "  hist = new_model.fit(client_train_x[num], client_train_y[num], epochs=2, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "  return new_model, lr, round(hist.history['val_loss'][-1], 4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X14df0oaLrN",
        "outputId": "4aba0f26-49b9-41ff-85d4-78ba30e15e61"
      },
      "source": [
        "losses "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2854,\n",
              " 0.3337,\n",
              " 0.342,\n",
              " 0.2697,\n",
              " 0.3304,\n",
              " 0.3228,\n",
              " 2.1346,\n",
              " 0.6184,\n",
              " 0.3967,\n",
              " 0.3158,\n",
              " 0.3289,\n",
              " 0.3517,\n",
              " 0.3863,\n",
              " 0.2941,\n",
              " 0.3156,\n",
              " 0.7884,\n",
              " 0.3185,\n",
              " 0.3142,\n",
              " 0.3163,\n",
              " 0.3289,\n",
              " 0.3051,\n",
              " 0.3316,\n",
              " 0.3199,\n",
              " 0.3202,\n",
              " 0.3599,\n",
              " 0.2834,\n",
              " 0.2479,\n",
              " 0.329,\n",
              " 0.2307,\n",
              " 0.2916]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MdhJtDYkZXW",
        "outputId": "4ca65a31-9e50-46b6-c54c-01ed8f7bfad1"
      },
      "source": [
        "lr_init "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 1e-05,\n",
              " 0.0001,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.0001,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.001,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.001]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSK_7dY0Tlx"
      },
      "source": [
        "yhat\n",
        "if(-1 in yhat):\n",
        "  flag=1\n",
        "else:\n",
        "  flag=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88GFprXB54KL"
      },
      "source": [
        "# Genetic Clustering FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJePiAuto7dJ",
        "outputId": "21c56a1d-aaf2-4077-ffae-6844d123ede0"
      },
      "source": [
        "yhat = list(yhat)\n",
        "serverhist1={\n",
        "    \"loss\": list(),\n",
        "    \"accuracy\": list()\n",
        "}\n",
        "# Control loop\n",
        "for i in range(NUM_ROUNDS):\n",
        "  print(\"---------\"+str(i)+\"------------\")\n",
        "  lr_global = []\n",
        "  #  Genetic Optimization of Hyper-Parameters\n",
        "  for cluster in clusters:\n",
        "    ind = [k for k in range(len(yhat)) if(yhat[k]==cluster)]\n",
        "    lr_global.append(evolve([losses[k] for k in ind], [lr_init[k] for k in ind]))\n",
        "\n",
        "  lr_init = []\n",
        "  losses = []\n",
        "  data = []\n",
        "  lrid = np.zeros(len(clusters))\n",
        "  for j in range(NUM_CLIENTS):\n",
        "    print(lrid)\n",
        "    data.append(train_client(j, server_model, lr_global[yhat[j]+flag][int(lrid[yhat[j]+flag])]))\n",
        "    lrid[yhat[j]+flag] +=1\n",
        "\n",
        "    client_models[j] = data[j][0]\n",
        "    losses.append(data[j][2])\n",
        "    lr_init.append(data[j][1])\n",
        "\n",
        "  # Cluster head aggregation\n",
        "  n_clust = len(set(yhat))\n",
        "  a = [[i*0 for i in client_models[0].get_weights()] for i in range(n_clust)]\n",
        "  for i in range(len(yhat)):\n",
        "    a[yhat[i]] = [k+j for k, j in zip(client_models[i].get_weights(), a[yhat[i]])]\n",
        "\n",
        "\n",
        "  # Aggregating model\n",
        "  sum=[i*0 for i in client_models[0].get_weights()]\n",
        "  for i in range(len(a)):\n",
        "    sum = [i+j for i, j in zip(a[i], sum)]\n",
        "  server_model.set_weights([i/NUM_CLIENTS for i in sum])\n",
        "\n",
        "  # Model Evaluation\n",
        "  h=server_model.evaluate(X_test,y_test)\n",
        "  serverhist1['loss'].append(h[1])\n",
        "  serverhist1['accuracy'].append(h[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------0------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.3844 - accuracy: 0.8928 - val_loss: 0.2302 - val_accuracy: 0.9303\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 13ms/step - loss: 0.1932 - accuracy: 0.9418 - val_loss: 0.2988 - val_accuracy: 0.9256\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.2017 - accuracy: 0.9413 - val_loss: 0.1726 - val_accuracy: 0.9491\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 14ms/step - loss: 0.0926 - accuracy: 0.9761 - val_loss: 0.1584 - val_accuracy: 0.9523\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 18ms/step - loss: 0.2035 - accuracy: 0.9404 - val_loss: 0.1744 - val_accuracy: 0.9482\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 16ms/step - loss: 0.1006 - accuracy: 0.9720 - val_loss: 0.1637 - val_accuracy: 0.9501\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.3965 - accuracy: 0.8802 - val_loss: 0.2680 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1716 - accuracy: 0.9440 - val_loss: 0.2757 - val_accuracy: 0.9288\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.3488 - accuracy: 0.8983 - val_loss: 0.3866 - val_accuracy: 0.8918\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.1563 - accuracy: 0.9508 - val_loss: 0.3847 - val_accuracy: 0.9170\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.3935 - accuracy: 0.8863 - val_loss: 0.3269 - val_accuracy: 0.9096\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.1582 - accuracy: 0.9508 - val_loss: 0.3465 - val_accuracy: 0.9262\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.2995 - accuracy: 0.9256 - val_loss: 0.2230 - val_accuracy: 0.9377\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 14ms/step - loss: 0.2044 - accuracy: 0.9404 - val_loss: 0.1977 - val_accuracy: 0.9430\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.2840 - accuracy: 0.9292 - val_loss: 0.2080 - val_accuracy: 0.9410\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.1877 - accuracy: 0.9450 - val_loss: 0.1851 - val_accuracy: 0.9466\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.3754 - accuracy: 0.8939 - val_loss: 0.2894 - val_accuracy: 0.9196\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.1490 - accuracy: 0.9495 - val_loss: 0.4290 - val_accuracy: 0.9043\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.1973 - accuracy: 0.9405 - val_loss: 0.1636 - val_accuracy: 0.9492\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.0890 - accuracy: 0.9742 - val_loss: 0.1399 - val_accuracy: 0.9573\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.2171 - accuracy: 0.9327 - val_loss: 0.1779 - val_accuracy: 0.9471\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.1001 - accuracy: 0.9738 - val_loss: 0.1734 - val_accuracy: 0.9487\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.3397 - accuracy: 0.9037 - val_loss: 0.1966 - val_accuracy: 0.9439\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.1763 - accuracy: 0.9454 - val_loss: 0.3747 - val_accuracy: 0.9219\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3894 - accuracy: 0.8865 - val_loss: 0.2722 - val_accuracy: 0.9207\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.1856 - accuracy: 0.9478 - val_loss: 0.3188 - val_accuracy: 0.9164\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 2s 12ms/step - loss: 0.3785 - accuracy: 0.8963 - val_loss: 0.2752 - val_accuracy: 0.9210\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.2012 - accuracy: 0.9409 - val_loss: 0.3193 - val_accuracy: 0.9155\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.3925 - accuracy: 0.8823 - val_loss: 0.2969 - val_accuracy: 0.9122\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 1s 12ms/step - loss: 0.1345 - accuracy: 0.9555 - val_loss: 0.3994 - val_accuracy: 0.9021\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 16ms/step - loss: 0.3288 - accuracy: 0.9301 - val_loss: 0.2573 - val_accuracy: 0.9329\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.2225 - accuracy: 0.9427 - val_loss: 0.2138 - val_accuracy: 0.9395\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.1916 - accuracy: 0.9448 - val_loss: 0.1565 - val_accuracy: 0.9521\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 10ms/step - loss: 0.0855 - accuracy: 0.9762 - val_loss: 0.1335 - val_accuracy: 0.9591\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.2009 - accuracy: 0.9384 - val_loss: 0.1745 - val_accuracy: 0.9477\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 0.1027 - accuracy: 0.9693 - val_loss: 0.1616 - val_accuracy: 0.9536\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 2s 13ms/step - loss: 0.1943 - accuracy: 0.9456 - val_loss: 0.1695 - val_accuracy: 0.9475\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 14ms/step - loss: 0.1033 - accuracy: 0.9727 - val_loss: 0.1422 - val_accuracy: 0.9565\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.2410 - accuracy: 0.9286 - val_loss: 0.1674 - val_accuracy: 0.9491\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 13ms/step - loss: 0.1158 - accuracy: 0.9648 - val_loss: 0.1510 - val_accuracy: 0.9536\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.3740 - accuracy: 0.8944 - val_loss: 0.5149 - val_accuracy: 0.8708\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.2444 - accuracy: 0.9291 - val_loss: 0.4047 - val_accuracy: 0.9142\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.2019 - accuracy: 0.9466 - val_loss: 0.1757 - val_accuracy: 0.9461\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.0906 - accuracy: 0.9759 - val_loss: 0.1515 - val_accuracy: 0.9540\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 16ms/step - loss: 0.3880 - accuracy: 0.8850 - val_loss: 0.3102 - val_accuracy: 0.9165\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 18ms/step - loss: 0.2017 - accuracy: 0.9435 - val_loss: 0.4290 - val_accuracy: 0.9084\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.3689 - accuracy: 0.8934 - val_loss: 0.2536 - val_accuracy: 0.9309\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.1026 - accuracy: 0.9623 - val_loss: 0.2433 - val_accuracy: 0.9351\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 17ms/step - loss: 0.3732 - accuracy: 0.8952 - val_loss: 0.3668 - val_accuracy: 0.9046\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 1s 12ms/step - loss: 0.2071 - accuracy: 0.9377 - val_loss: 0.3583 - val_accuracy: 0.9172\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.2111 - accuracy: 0.9402 - val_loss: 0.1591 - val_accuracy: 0.9536\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.1039 - accuracy: 0.9709 - val_loss: 0.1393 - val_accuracy: 0.9586\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.3886 - accuracy: 0.8873 - val_loss: 0.3182 - val_accuracy: 0.9122\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 9ms/step - loss: 0.2000 - accuracy: 0.9467 - val_loss: 0.3216 - val_accuracy: 0.9255\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.3355 - accuracy: 0.8988 - val_loss: 0.2620 - val_accuracy: 0.9274\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 0.1995 - accuracy: 0.9425 - val_loss: 0.6487 - val_accuracy: 0.8865\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3467 - accuracy: 0.8945 - val_loss: 0.2746 - val_accuracy: 0.9230\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 9ms/step - loss: 0.1680 - accuracy: 0.9520 - val_loss: 0.4884 - val_accuracy: 0.8967\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.1897 - accuracy: 0.9433 - val_loss: 0.1589 - val_accuracy: 0.9520\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0876 - accuracy: 0.9776 - val_loss: 0.1487 - val_accuracy: 0.9532\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1263 - accuracy: 0.9621\n",
            "---------1------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.2927 - accuracy: 0.9195 - val_loss: 0.2224 - val_accuracy: 0.9344\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 13ms/step - loss: 0.1704 - accuracy: 0.9514 - val_loss: 0.3273 - val_accuracy: 0.9274\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.1105 - accuracy: 0.9653 - val_loss: 0.1103 - val_accuracy: 0.9684\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 18ms/step - loss: 0.0449 - accuracy: 0.9901 - val_loss: 0.1136 - val_accuracy: 0.9659\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 14ms/step - loss: 0.1115 - accuracy: 0.9686 - val_loss: 0.1096 - val_accuracy: 0.9674\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 1s 12ms/step - loss: 0.0527 - accuracy: 0.9854 - val_loss: 0.1083 - val_accuracy: 0.9686\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.3285 - accuracy: 0.9097 - val_loss: 0.2249 - val_accuracy: 0.9353\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.1954 - accuracy: 0.9424 - val_loss: 0.5619 - val_accuracy: 0.8890\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.2556 - accuracy: 0.9325 - val_loss: 0.2665 - val_accuracy: 0.9271\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.1139 - accuracy: 0.9661 - val_loss: 0.4938 - val_accuracy: 0.9076\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.2546 - accuracy: 0.9238 - val_loss: 0.3624 - val_accuracy: 0.9148\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.1621 - accuracy: 0.9532 - val_loss: 0.3086 - val_accuracy: 0.9383\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 0.1276 - accuracy: 0.9602 - val_loss: 0.1118 - val_accuracy: 0.9664\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 14ms/step - loss: 0.1047 - accuracy: 0.9666 - val_loss: 0.1101 - val_accuracy: 0.9668\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.1179 - accuracy: 0.9666 - val_loss: 0.1102 - val_accuracy: 0.9666\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.0969 - accuracy: 0.9713 - val_loss: 0.1088 - val_accuracy: 0.9679\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.3553 - accuracy: 0.9091 - val_loss: 0.2643 - val_accuracy: 0.9263\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.1476 - accuracy: 0.9534 - val_loss: 0.3422 - val_accuracy: 0.9226\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.1113 - accuracy: 0.9654 - val_loss: 0.1085 - val_accuracy: 0.9682\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.0454 - accuracy: 0.9869 - val_loss: 0.1073 - val_accuracy: 0.9678\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.1156 - accuracy: 0.9649 - val_loss: 0.1277 - val_accuracy: 0.9623\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.0494 - accuracy: 0.9872 - val_loss: 0.1144 - val_accuracy: 0.9674\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3687 - accuracy: 0.9075 - val_loss: 0.3477 - val_accuracy: 0.9095\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.2880 - accuracy: 0.9339 - val_loss: 0.5545 - val_accuracy: 0.9169\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.3513 - accuracy: 0.9092 - val_loss: 0.5433 - val_accuracy: 0.8866\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.2773 - accuracy: 0.9328 - val_loss: 0.4475 - val_accuracy: 0.9090\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.3620 - accuracy: 0.9090 - val_loss: 0.2498 - val_accuracy: 0.9284\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.1924 - accuracy: 0.9478 - val_loss: 0.9038 - val_accuracy: 0.8777\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 13ms/step - loss: 0.3058 - accuracy: 0.9159 - val_loss: 0.4351 - val_accuracy: 0.8805\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.1675 - accuracy: 0.9522 - val_loss: 0.3437 - val_accuracy: 0.9264\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.1107 - accuracy: 0.9671 - val_loss: 0.1134 - val_accuracy: 0.9659\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.0976 - accuracy: 0.9716 - val_loss: 0.1101 - val_accuracy: 0.9662\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.1073 - accuracy: 0.9663 - val_loss: 0.1024 - val_accuracy: 0.9683\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.0454 - accuracy: 0.9877 - val_loss: 0.1040 - val_accuracy: 0.9704\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 0.1106 - accuracy: 0.9649 - val_loss: 0.1087 - val_accuracy: 0.9669\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.1061 - val_accuracy: 0.9687\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.1125 - accuracy: 0.9678 - val_loss: 0.1048 - val_accuracy: 0.9686\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.0477 - accuracy: 0.9888 - val_loss: 0.0999 - val_accuracy: 0.9699\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.1372 - accuracy: 0.9576 - val_loss: 0.1063 - val_accuracy: 0.9670\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.0592 - accuracy: 0.9844 - val_loss: 0.1044 - val_accuracy: 0.9697\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.3319 - accuracy: 0.9130 - val_loss: 0.3278 - val_accuracy: 0.9245\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.3106 - accuracy: 0.9254 - val_loss: 0.4290 - val_accuracy: 0.9172\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.0933 - accuracy: 0.9729 - val_loss: 0.1113 - val_accuracy: 0.9653\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.1044 - val_accuracy: 0.9686\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 16ms/step - loss: 0.3587 - accuracy: 0.9103 - val_loss: 0.4230 - val_accuracy: 0.8993\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 14ms/step - loss: 0.1596 - accuracy: 0.9518 - val_loss: 0.3532 - val_accuracy: 0.9285\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.3520 - accuracy: 0.9094 - val_loss: 0.4708 - val_accuracy: 0.8947\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.2936 - accuracy: 0.9284 - val_loss: 0.3564 - val_accuracy: 0.9297\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.3024 - accuracy: 0.9208 - val_loss: 0.3736 - val_accuracy: 0.9077\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.1677 - accuracy: 0.9494 - val_loss: 0.3185 - val_accuracy: 0.9348\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.1217 - accuracy: 0.9644 - val_loss: 0.0981 - val_accuracy: 0.9696\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.0580 - accuracy: 0.9840 - val_loss: 0.0967 - val_accuracy: 0.9705\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3661 - accuracy: 0.9041 - val_loss: 0.3703 - val_accuracy: 0.9021\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.1910 - accuracy: 0.9483 - val_loss: 0.2967 - val_accuracy: 0.9346\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.3266 - accuracy: 0.9111 - val_loss: 0.3167 - val_accuracy: 0.9131\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 0.1790 - accuracy: 0.9519 - val_loss: 0.2824 - val_accuracy: 0.9362\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3130 - accuracy: 0.9127 - val_loss: 0.2305 - val_accuracy: 0.9396\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 9ms/step - loss: 0.2075 - accuracy: 0.9412 - val_loss: 0.4411 - val_accuracy: 0.9217\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.0957 - accuracy: 0.9720 - val_loss: 0.1044 - val_accuracy: 0.9685\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0390 - accuracy: 0.9920 - val_loss: 0.1065 - val_accuracy: 0.9686\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9707\n",
            "---------2------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.3343 - accuracy: 0.9218 - val_loss: 0.4649 - val_accuracy: 0.8988\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 14ms/step - loss: 0.2094 - accuracy: 0.9451 - val_loss: 0.3167 - val_accuracy: 0.9346\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.0859 - accuracy: 0.9735 - val_loss: 0.0946 - val_accuracy: 0.9713\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 14ms/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 0.0888 - val_accuracy: 0.9746\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 18ms/step - loss: 0.0947 - accuracy: 0.9726 - val_loss: 0.0937 - val_accuracy: 0.9728\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 16ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0924 - val_accuracy: 0.9727\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 0.3528 - accuracy: 0.9143 - val_loss: 0.5468 - val_accuracy: 0.8800\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.2656 - accuracy: 0.9346 - val_loss: 0.4114 - val_accuracy: 0.9322\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.3769 - accuracy: 0.9227 - val_loss: 0.5512 - val_accuracy: 0.9051\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.3779 - accuracy: 0.9301 - val_loss: 0.7148 - val_accuracy: 0.9015\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.2285 - accuracy: 0.9446 - val_loss: 0.3042 - val_accuracy: 0.9259\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.1570 - accuracy: 0.9626 - val_loss: 0.4566 - val_accuracy: 0.9233\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.0995 - accuracy: 0.9686 - val_loss: 0.0894 - val_accuracy: 0.9718\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 14ms/step - loss: 0.0842 - accuracy: 0.9729 - val_loss: 0.0886 - val_accuracy: 0.9722\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.0912 - accuracy: 0.9722 - val_loss: 0.0883 - val_accuracy: 0.9723\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 10ms/step - loss: 0.0752 - accuracy: 0.9778 - val_loss: 0.0882 - val_accuracy: 0.9729\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.3504 - accuracy: 0.9175 - val_loss: 0.3743 - val_accuracy: 0.9108\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.2426 - accuracy: 0.9408 - val_loss: 0.4832 - val_accuracy: 0.9268\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.0898 - accuracy: 0.9733 - val_loss: 0.0857 - val_accuracy: 0.9744\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.0397 - accuracy: 0.9878 - val_loss: 0.0872 - val_accuracy: 0.9740\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.0972 - accuracy: 0.9728 - val_loss: 0.0901 - val_accuracy: 0.9732\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.0927 - val_accuracy: 0.9730\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2250 - accuracy: 0.9391 - val_loss: 0.2879 - val_accuracy: 0.9308\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1446 - accuracy: 0.9600 - val_loss: 0.2771 - val_accuracy: 0.9452\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3054 - accuracy: 0.9268 - val_loss: 0.3120 - val_accuracy: 0.9338\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.1814 - accuracy: 0.9554 - val_loss: 0.2812 - val_accuracy: 0.9443\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.3923 - accuracy: 0.9169 - val_loss: 0.5095 - val_accuracy: 0.9086\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.2742 - accuracy: 0.9381 - val_loss: 0.4555 - val_accuracy: 0.9189\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 13ms/step - loss: 0.2274 - accuracy: 0.9358 - val_loss: 0.3328 - val_accuracy: 0.9163\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.1669 - accuracy: 0.9555 - val_loss: 0.4766 - val_accuracy: 0.9192\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 16ms/step - loss: 0.0811 - accuracy: 0.9760 - val_loss: 0.0904 - val_accuracy: 0.9717\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.0705 - accuracy: 0.9778 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.0813 - accuracy: 0.9749 - val_loss: 0.0851 - val_accuracy: 0.9734\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 10ms/step - loss: 0.0324 - accuracy: 0.9898 - val_loss: 0.0884 - val_accuracy: 0.9750\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.0868 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9728\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 0.0384 - accuracy: 0.9891 - val_loss: 0.0904 - val_accuracy: 0.9727\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.0945 - accuracy: 0.9729 - val_loss: 0.0828 - val_accuracy: 0.9741\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 11ms/step - loss: 0.0424 - accuracy: 0.9890 - val_loss: 0.0863 - val_accuracy: 0.9731\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 20ms/step - loss: 0.1129 - accuracy: 0.9679 - val_loss: 0.0839 - val_accuracy: 0.9746\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 14ms/step - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.0835 - val_accuracy: 0.9741\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.2571 - accuracy: 0.9341 - val_loss: 0.3963 - val_accuracy: 0.8926\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.1437 - accuracy: 0.9614 - val_loss: 0.3114 - val_accuracy: 0.9382\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.0677 - accuracy: 0.9770 - val_loss: 0.0884 - val_accuracy: 0.9731\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.0892 - val_accuracy: 0.9738\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 20ms/step - loss: 0.2778 - accuracy: 0.9295 - val_loss: 0.4960 - val_accuracy: 0.9044\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 14ms/step - loss: 0.1886 - accuracy: 0.9535 - val_loss: 0.3210 - val_accuracy: 0.9362\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.2770 - accuracy: 0.9311 - val_loss: 0.6973 - val_accuracy: 0.8616\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.3781 - accuracy: 0.9293 - val_loss: 0.4987 - val_accuracy: 0.9134\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.3171 - accuracy: 0.9272 - val_loss: 0.3739 - val_accuracy: 0.9188\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 1s 12ms/step - loss: 0.2190 - accuracy: 0.9466 - val_loss: 0.4737 - val_accuracy: 0.9123\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.0963 - accuracy: 0.9714 - val_loss: 0.0843 - val_accuracy: 0.9736\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.0409 - accuracy: 0.9882 - val_loss: 0.0835 - val_accuracy: 0.9747\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2750 - accuracy: 0.9289 - val_loss: 0.2995 - val_accuracy: 0.9244\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.1719 - accuracy: 0.9571 - val_loss: 0.3548 - val_accuracy: 0.9286\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.3140 - accuracy: 0.9255 - val_loss: 0.5263 - val_accuracy: 0.8974\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.2145 - accuracy: 0.9456 - val_loss: 0.3746 - val_accuracy: 0.9416\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.4382 - accuracy: 0.9055 - val_loss: 0.5944 - val_accuracy: 0.8916\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.1831 - accuracy: 0.9486 - val_loss: 0.4063 - val_accuracy: 0.9217\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.0742 - accuracy: 0.9806 - val_loss: 0.0905 - val_accuracy: 0.9716\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0306 - accuracy: 0.9928 - val_loss: 0.0871 - val_accuracy: 0.9744\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9719\n",
            "---------3------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.2576 - accuracy: 0.9445 - val_loss: 0.2076 - val_accuracy: 0.9508\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.1448 - accuracy: 0.9639 - val_loss: 0.3663 - val_accuracy: 0.9270\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.0820 - accuracy: 0.9755 - val_loss: 0.0811 - val_accuracy: 0.9758\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 14ms/step - loss: 0.0298 - accuracy: 0.9936 - val_loss: 0.0839 - val_accuracy: 0.9763\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 18ms/step - loss: 0.0883 - accuracy: 0.9759 - val_loss: 0.0835 - val_accuracy: 0.9758\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 1s 12ms/step - loss: 0.0387 - accuracy: 0.9882 - val_loss: 0.0903 - val_accuracy: 0.9757\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 0.2720 - accuracy: 0.9362 - val_loss: 0.3047 - val_accuracy: 0.9297\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.2053 - accuracy: 0.9539 - val_loss: 0.4532 - val_accuracy: 0.9175\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.1452 - accuracy: 0.9652 - val_loss: 0.3209 - val_accuracy: 0.9412\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.2170 - accuracy: 0.9599 - val_loss: 0.5160 - val_accuracy: 0.9269\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 0.3506 - accuracy: 0.9326 - val_loss: 0.4567 - val_accuracy: 0.9323\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.2419 - accuracy: 0.9505 - val_loss: 0.4940 - val_accuracy: 0.9383\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.0881 - accuracy: 0.9723 - val_loss: 0.0828 - val_accuracy: 0.9753\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 11ms/step - loss: 0.0733 - accuracy: 0.9768 - val_loss: 0.0826 - val_accuracy: 0.9762\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.0834 - accuracy: 0.9746 - val_loss: 0.0823 - val_accuracy: 0.9753\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.0691 - accuracy: 0.9796 - val_loss: 0.0816 - val_accuracy: 0.9758\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.2503 - accuracy: 0.9444 - val_loss: 0.3669 - val_accuracy: 0.9099\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.1828 - accuracy: 0.9593 - val_loss: 0.4024 - val_accuracy: 0.9404\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.0833 - accuracy: 0.9770 - val_loss: 0.0825 - val_accuracy: 0.9765\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.0768 - val_accuracy: 0.9783\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.0848 - accuracy: 0.9731 - val_loss: 0.0872 - val_accuracy: 0.9756\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.0352 - accuracy: 0.9895 - val_loss: 0.0867 - val_accuracy: 0.9756\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2740 - accuracy: 0.9387 - val_loss: 0.3257 - val_accuracy: 0.9345\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2476 - accuracy: 0.9485 - val_loss: 0.3671 - val_accuracy: 0.9346\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.4039 - accuracy: 0.9256 - val_loss: 0.5507 - val_accuracy: 0.8899\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.3147 - accuracy: 0.9400 - val_loss: 0.4844 - val_accuracy: 0.9148\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 2s 13ms/step - loss: 0.2868 - accuracy: 0.9339 - val_loss: 0.5274 - val_accuracy: 0.8988\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.3305 - accuracy: 0.9402 - val_loss: 0.7573 - val_accuracy: 0.8864\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.1877 - accuracy: 0.9505 - val_loss: 0.2184 - val_accuracy: 0.9435\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.1319 - accuracy: 0.9679 - val_loss: 0.6338 - val_accuracy: 0.9031\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0697 - accuracy: 0.9780 - val_loss: 0.0826 - val_accuracy: 0.9753\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 12ms/step - loss: 0.0584 - accuracy: 0.9817 - val_loss: 0.0814 - val_accuracy: 0.9757\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.0845 - val_accuracy: 0.9741\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0811 - val_accuracy: 0.9764\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.0751 - accuracy: 0.9784 - val_loss: 0.0869 - val_accuracy: 0.9757\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.0299 - accuracy: 0.9907 - val_loss: 0.0864 - val_accuracy: 0.9751\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.0922 - accuracy: 0.9767 - val_loss: 0.0778 - val_accuracy: 0.9762\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 12ms/step - loss: 0.0371 - accuracy: 0.9914 - val_loss: 0.0799 - val_accuracy: 0.9775\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 20ms/step - loss: 0.1084 - accuracy: 0.9695 - val_loss: 0.0784 - val_accuracy: 0.9779\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 13ms/step - loss: 0.0432 - accuracy: 0.9888 - val_loss: 0.0784 - val_accuracy: 0.9770\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.3674 - accuracy: 0.9265 - val_loss: 0.6169 - val_accuracy: 0.9032\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.4571 - accuracy: 0.9278 - val_loss: 0.5037 - val_accuracy: 0.9356\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 0.0818 - val_accuracy: 0.9750\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.0867 - val_accuracy: 0.9772\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 16ms/step - loss: 0.3268 - accuracy: 0.9319 - val_loss: 0.6160 - val_accuracy: 0.9178\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 14ms/step - loss: 0.3361 - accuracy: 0.9418 - val_loss: 0.4075 - val_accuracy: 0.9400\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.2470 - accuracy: 0.9400 - val_loss: 0.2878 - val_accuracy: 0.9376\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.1942 - accuracy: 0.9549 - val_loss: 0.4780 - val_accuracy: 0.9279\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.2969 - accuracy: 0.9333 - val_loss: 0.3201 - val_accuracy: 0.9318\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 1s 12ms/step - loss: 0.2433 - accuracy: 0.9479 - val_loss: 0.4957 - val_accuracy: 0.9110\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.0761 - val_accuracy: 0.9776\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 10ms/step - loss: 0.0327 - accuracy: 0.9899 - val_loss: 0.0820 - val_accuracy: 0.9779\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2687 - accuracy: 0.9357 - val_loss: 0.2852 - val_accuracy: 0.9366\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.3237 - accuracy: 0.9386 - val_loss: 0.5477 - val_accuracy: 0.9268\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.3084 - accuracy: 0.9338 - val_loss: 0.4542 - val_accuracy: 0.9370\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 0.3945 - accuracy: 0.9356 - val_loss: 0.3584 - val_accuracy: 0.9446\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3067 - accuracy: 0.9340 - val_loss: 0.3839 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.2496 - accuracy: 0.9456 - val_loss: 0.7393 - val_accuracy: 0.9047\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.0624 - accuracy: 0.9850 - val_loss: 0.0814 - val_accuracy: 0.9768\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.0812 - val_accuracy: 0.9775\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9743\n",
            "---------4------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.3557 - accuracy: 0.9291 - val_loss: 0.5898 - val_accuracy: 0.8929\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 14ms/step - loss: 0.3229 - accuracy: 0.9426 - val_loss: 0.4271 - val_accuracy: 0.9287\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.0778 - accuracy: 0.9806 - val_loss: 0.0818 - val_accuracy: 0.9770\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 13ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.0795 - val_accuracy: 0.9781\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 14ms/step - loss: 0.0881 - accuracy: 0.9762 - val_loss: 0.0880 - val_accuracy: 0.9770\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 0.0874 - val_accuracy: 0.9772\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 0.1586 - accuracy: 0.9581 - val_loss: 0.2680 - val_accuracy: 0.9565\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.2153 - accuracy: 0.9568 - val_loss: 0.4056 - val_accuracy: 0.9287\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.3538 - accuracy: 0.9419 - val_loss: 0.5643 - val_accuracy: 0.9341\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.3921 - accuracy: 0.9428 - val_loss: 0.7781 - val_accuracy: 0.9185\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.2513 - accuracy: 0.9481 - val_loss: 0.6622 - val_accuracy: 0.8977\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.3296 - accuracy: 0.9478 - val_loss: 0.7654 - val_accuracy: 0.9153\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.0831 - accuracy: 0.9761 - val_loss: 0.0818 - val_accuracy: 0.9763\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 14ms/step - loss: 0.0696 - accuracy: 0.9804 - val_loss: 0.0812 - val_accuracy: 0.9768\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.0800 - accuracy: 0.9763 - val_loss: 0.0812 - val_accuracy: 0.9768\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 10ms/step - loss: 0.0673 - accuracy: 0.9804 - val_loss: 0.0796 - val_accuracy: 0.9771\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.2408 - accuracy: 0.9492 - val_loss: 0.3553 - val_accuracy: 0.9389\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.2267 - accuracy: 0.9578 - val_loss: 0.5399 - val_accuracy: 0.9288\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.0821 - accuracy: 0.9768 - val_loss: 0.0869 - val_accuracy: 0.9776\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 0.0876 - val_accuracy: 0.9777\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 0.0832 - accuracy: 0.9757 - val_loss: 0.0821 - val_accuracy: 0.9775\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.0321 - accuracy: 0.9908 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3899 - accuracy: 0.9275 - val_loss: 0.4042 - val_accuracy: 0.9267\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.2551 - accuracy: 0.9435 - val_loss: 0.4327 - val_accuracy: 0.9362\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3141 - accuracy: 0.9446 - val_loss: 0.4632 - val_accuracy: 0.8850\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.1816 - accuracy: 0.9576 - val_loss: 0.4033 - val_accuracy: 0.9356\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.2595 - accuracy: 0.9455 - val_loss: 0.6329 - val_accuracy: 0.8975\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.2020 - accuracy: 0.9573 - val_loss: 0.5908 - val_accuracy: 0.9327\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.3268 - accuracy: 0.9391 - val_loss: 0.4676 - val_accuracy: 0.9218\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 1s 12ms/step - loss: 0.3351 - accuracy: 0.9411 - val_loss: 0.5178 - val_accuracy: 0.9238\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0626 - accuracy: 0.9795 - val_loss: 0.0829 - val_accuracy: 0.9769\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.0526 - accuracy: 0.9830 - val_loss: 0.0817 - val_accuracy: 0.9772\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 2s 11ms/step - loss: 0.0627 - accuracy: 0.9826 - val_loss: 0.0788 - val_accuracy: 0.9775\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0828 - val_accuracy: 0.9764\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.0659 - accuracy: 0.9812 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.0830 - val_accuracy: 0.9772\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.0926 - accuracy: 0.9783 - val_loss: 0.0774 - val_accuracy: 0.9772\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.0461 - accuracy: 0.9869 - val_loss: 0.0775 - val_accuracy: 0.9794\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 20ms/step - loss: 0.1065 - accuracy: 0.9748 - val_loss: 0.0829 - val_accuracy: 0.9786\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 14ms/step - loss: 0.0479 - accuracy: 0.9878 - val_loss: 0.0839 - val_accuracy: 0.9781\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.3113 - accuracy: 0.9410 - val_loss: 0.6184 - val_accuracy: 0.9218\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 14ms/step - loss: 0.2788 - accuracy: 0.9516 - val_loss: 0.4984 - val_accuracy: 0.9374\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 18ms/step - loss: 0.0514 - accuracy: 0.9867 - val_loss: 0.0784 - val_accuracy: 0.9774\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 13ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.0932 - val_accuracy: 0.9788\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.2354 - accuracy: 0.9508 - val_loss: 0.7123 - val_accuracy: 0.9063\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 19ms/step - loss: 0.2596 - accuracy: 0.9492 - val_loss: 0.6807 - val_accuracy: 0.9198\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.2212 - accuracy: 0.9456 - val_loss: 0.6003 - val_accuracy: 0.8982\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.2308 - accuracy: 0.9557 - val_loss: 0.4557 - val_accuracy: 0.9316\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.3101 - accuracy: 0.9410 - val_loss: 0.8596 - val_accuracy: 0.9038\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.4758 - accuracy: 0.9343 - val_loss: 0.5803 - val_accuracy: 0.9219\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.0782 - accuracy: 0.9772 - val_loss: 0.0753 - val_accuracy: 0.9772\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 10ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.0779 - val_accuracy: 0.9801\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 2s 11ms/step - loss: 0.2957 - accuracy: 0.9386 - val_loss: 0.3266 - val_accuracy: 0.9306\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.2400 - accuracy: 0.9523 - val_loss: 0.3715 - val_accuracy: 0.9287\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.2748 - accuracy: 0.9396 - val_loss: 1.0459 - val_accuracy: 0.8705\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.3506 - accuracy: 0.9423 - val_loss: 0.5334 - val_accuracy: 0.9188\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3394 - accuracy: 0.9295 - val_loss: 0.2953 - val_accuracy: 0.9397\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.2545 - accuracy: 0.9439 - val_loss: 0.5941 - val_accuracy: 0.9070\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 0.0789 - val_accuracy: 0.9763\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.0881 - val_accuracy: 0.9785\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0878 - accuracy: 0.9763\n",
            "---------5------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.2918 - accuracy: 0.9468 - val_loss: 0.3559 - val_accuracy: 0.9246\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 14ms/step - loss: 0.2003 - accuracy: 0.9595 - val_loss: 0.3754 - val_accuracy: 0.9340\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.0834 - accuracy: 0.9783 - val_loss: 0.0823 - val_accuracy: 0.9795\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 14ms/step - loss: 0.0366 - accuracy: 0.9914 - val_loss: 0.0810 - val_accuracy: 0.9780\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 18ms/step - loss: 0.0909 - accuracy: 0.9776 - val_loss: 0.0899 - val_accuracy: 0.9754\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 1s 13ms/step - loss: 0.0405 - accuracy: 0.9882 - val_loss: 0.0894 - val_accuracy: 0.9771\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.1986 - accuracy: 0.9519 - val_loss: 0.2725 - val_accuracy: 0.9480\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.4183 - accuracy: 0.9398 - val_loss: 0.7028 - val_accuracy: 0.9230\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.1926 - accuracy: 0.9623 - val_loss: 0.4955 - val_accuracy: 0.9287\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.2724 - accuracy: 0.9575 - val_loss: 0.5816 - val_accuracy: 0.9470\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.1379 - accuracy: 0.9711 - val_loss: 0.2898 - val_accuracy: 0.9530\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.2330 - accuracy: 0.9599 - val_loss: 1.2772 - val_accuracy: 0.9011\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.0856 - accuracy: 0.9786 - val_loss: 0.0839 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 0.0718 - accuracy: 0.9807 - val_loss: 0.0822 - val_accuracy: 0.9781\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.0794 - accuracy: 0.9765 - val_loss: 0.0839 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.0667 - accuracy: 0.9805 - val_loss: 0.0824 - val_accuracy: 0.9776\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.2408 - accuracy: 0.9570 - val_loss: 0.5050 - val_accuracy: 0.9185\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.2542 - accuracy: 0.9555 - val_loss: 0.4876 - val_accuracy: 0.9289\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.0851 - accuracy: 0.9783 - val_loss: 0.0876 - val_accuracy: 0.9779\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 0.0841 - val_accuracy: 0.9787\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.0896 - accuracy: 0.9747 - val_loss: 0.0846 - val_accuracy: 0.9787\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.0357 - accuracy: 0.9898 - val_loss: 0.0849 - val_accuracy: 0.9775\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3330 - accuracy: 0.9439 - val_loss: 0.4888 - val_accuracy: 0.9394\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.2222 - accuracy: 0.9592 - val_loss: 0.3364 - val_accuracy: 0.9559\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2615 - accuracy: 0.9480 - val_loss: 0.4527 - val_accuracy: 0.9364\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.2744 - accuracy: 0.9530 - val_loss: 0.6529 - val_accuracy: 0.9136\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.3221 - accuracy: 0.9423 - val_loss: 1.4701 - val_accuracy: 0.8637\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.3605 - accuracy: 0.9460 - val_loss: 0.4208 - val_accuracy: 0.9373\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 0.2233 - accuracy: 0.9540 - val_loss: 0.5346 - val_accuracy: 0.9115\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.1984 - accuracy: 0.9591 - val_loss: 0.4309 - val_accuracy: 0.9393\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.0601 - accuracy: 0.9817 - val_loss: 0.0853 - val_accuracy: 0.9784\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0497 - accuracy: 0.9847 - val_loss: 0.0847 - val_accuracy: 0.9781\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.0594 - accuracy: 0.9824 - val_loss: 0.0813 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 10ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.0851 - val_accuracy: 0.9781\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.0658 - accuracy: 0.9812 - val_loss: 0.0812 - val_accuracy: 0.9789\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0894 - val_accuracy: 0.9782\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.0973 - accuracy: 0.9778 - val_loss: 0.0791 - val_accuracy: 0.9782\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.0402 - accuracy: 0.9904 - val_loss: 0.0831 - val_accuracy: 0.9798\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 20ms/step - loss: 0.1192 - accuracy: 0.9710 - val_loss: 0.0792 - val_accuracy: 0.9797\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.0607 - accuracy: 0.9841 - val_loss: 0.0792 - val_accuracy: 0.9776\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 2s 13ms/step - loss: 0.2928 - accuracy: 0.9462 - val_loss: 0.5635 - val_accuracy: 0.9321\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 14ms/step - loss: 0.4119 - accuracy: 0.9469 - val_loss: 0.9302 - val_accuracy: 0.9140\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 18ms/step - loss: 0.0476 - accuracy: 0.9870 - val_loss: 0.0865 - val_accuracy: 0.9793\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0866 - val_accuracy: 0.9786\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 3s 17ms/step - loss: 0.2531 - accuracy: 0.9545 - val_loss: 0.3859 - val_accuracy: 0.9265\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 19ms/step - loss: 0.5610 - accuracy: 0.9249 - val_loss: 0.8896 - val_accuracy: 0.9208\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 19ms/step - loss: 0.3447 - accuracy: 0.9412 - val_loss: 0.7914 - val_accuracy: 0.9119\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.4846 - accuracy: 0.9379 - val_loss: 0.6516 - val_accuracy: 0.9311\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.2801 - accuracy: 0.9494 - val_loss: 0.6343 - val_accuracy: 0.9156\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 12ms/step - loss: 0.4089 - accuracy: 0.9405 - val_loss: 0.6644 - val_accuracy: 0.9128\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.0780 - accuracy: 0.9794 - val_loss: 0.0790 - val_accuracy: 0.9812\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0797 - val_accuracy: 0.9809\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2013 - accuracy: 0.9552 - val_loss: 0.4249 - val_accuracy: 0.9273\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.1955 - accuracy: 0.9581 - val_loss: 0.3539 - val_accuracy: 0.9468\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.2769 - accuracy: 0.9427 - val_loss: 0.4992 - val_accuracy: 0.9359\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.3446 - accuracy: 0.9434 - val_loss: 0.7634 - val_accuracy: 0.9122\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3117 - accuracy: 0.9406 - val_loss: 0.3270 - val_accuracy: 0.9357\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.2770 - accuracy: 0.9449 - val_loss: 0.6016 - val_accuracy: 0.9167\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 16ms/step - loss: 0.0529 - accuracy: 0.9878 - val_loss: 0.0853 - val_accuracy: 0.9789\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.0884 - val_accuracy: 0.9776\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0891 - accuracy: 0.9773\n",
            "---------6------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.2647 - accuracy: 0.9531 - val_loss: 0.2900 - val_accuracy: 0.9482\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 14ms/step - loss: 0.2873 - accuracy: 0.9476 - val_loss: 0.7948 - val_accuracy: 0.9188\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.0879 - accuracy: 0.9777 - val_loss: 0.0842 - val_accuracy: 0.9785\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 14ms/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 0.0867 - val_accuracy: 0.9784\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 19ms/step - loss: 0.0921 - accuracy: 0.9773 - val_loss: 0.0912 - val_accuracy: 0.9771\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 1s 13ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.0889 - val_accuracy: 0.9779\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.1561 - accuracy: 0.9620 - val_loss: 0.3329 - val_accuracy: 0.9478\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.1796 - accuracy: 0.9656 - val_loss: 0.3433 - val_accuracy: 0.9520\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.2307 - accuracy: 0.9643 - val_loss: 0.5495 - val_accuracy: 0.9228\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.4079 - accuracy: 0.9510 - val_loss: 2.2450 - val_accuracy: 0.8902\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 15ms/step - loss: 0.2021 - accuracy: 0.9652 - val_loss: 0.6636 - val_accuracy: 0.9135\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.2993 - accuracy: 0.9540 - val_loss: 1.1843 - val_accuracy: 0.9014\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 2s 13ms/step - loss: 0.0864 - accuracy: 0.9786 - val_loss: 0.0869 - val_accuracy: 0.9790\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 15ms/step - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.0860 - val_accuracy: 0.9795\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.0808 - accuracy: 0.9787 - val_loss: 0.0868 - val_accuracy: 0.9782\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 10ms/step - loss: 0.0685 - accuracy: 0.9809 - val_loss: 0.0859 - val_accuracy: 0.9784\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.1837 - accuracy: 0.9653 - val_loss: 0.6001 - val_accuracy: 0.9137\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.2313 - accuracy: 0.9653 - val_loss: 0.3808 - val_accuracy: 0.9563\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.0847 - accuracy: 0.9805 - val_loss: 0.0905 - val_accuracy: 0.9765\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0909 - val_accuracy: 0.9797\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.0847 - accuracy: 0.9777 - val_loss: 0.0942 - val_accuracy: 0.9774\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.0934 - val_accuracy: 0.9779\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.1943 - accuracy: 0.9603 - val_loss: 0.3703 - val_accuracy: 0.9369\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2370 - accuracy: 0.9576 - val_loss: 0.6091 - val_accuracy: 0.9380\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3437 - accuracy: 0.9461 - val_loss: 0.7623 - val_accuracy: 0.9076\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.5000 - accuracy: 0.9428 - val_loss: 1.0289 - val_accuracy: 0.9057\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.2895 - accuracy: 0.9510 - val_loss: 0.4560 - val_accuracy: 0.9137\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.4822 - accuracy: 0.9358 - val_loss: 1.1607 - val_accuracy: 0.9301\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.2498 - accuracy: 0.9558 - val_loss: 0.2955 - val_accuracy: 0.9455\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 13ms/step - loss: 0.2353 - accuracy: 0.9603 - val_loss: 0.3902 - val_accuracy: 0.9413\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.0594 - accuracy: 0.9830 - val_loss: 0.0879 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 0.0495 - accuracy: 0.9844 - val_loss: 0.0876 - val_accuracy: 0.9782\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.0585 - accuracy: 0.9830 - val_loss: 0.0835 - val_accuracy: 0.9792\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0880 - val_accuracy: 0.9782\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 0.0652 - accuracy: 0.9826 - val_loss: 0.0869 - val_accuracy: 0.9796\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.0882 - val_accuracy: 0.9792\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.0971 - accuracy: 0.9797 - val_loss: 0.0822 - val_accuracy: 0.9782\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.0387 - accuracy: 0.9904 - val_loss: 0.0851 - val_accuracy: 0.9789\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 20ms/step - loss: 0.1236 - accuracy: 0.9720 - val_loss: 0.0800 - val_accuracy: 0.9791\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.0610 - accuracy: 0.9863 - val_loss: 0.0799 - val_accuracy: 0.9797\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.3987 - accuracy: 0.9451 - val_loss: 0.6326 - val_accuracy: 0.9323\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 14ms/step - loss: 0.4439 - accuracy: 0.9460 - val_loss: 0.8755 - val_accuracy: 0.9149\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 19ms/step - loss: 0.0469 - accuracy: 0.9898 - val_loss: 0.0936 - val_accuracy: 0.9779\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.1065 - val_accuracy: 0.9775\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.2083 - accuracy: 0.9598 - val_loss: 0.6058 - val_accuracy: 0.9324\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 15ms/step - loss: 0.4013 - accuracy: 0.9518 - val_loss: 0.6393 - val_accuracy: 0.9247\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.1828 - accuracy: 0.9641 - val_loss: 0.3012 - val_accuracy: 0.9457\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.2900 - accuracy: 0.9498 - val_loss: 0.7561 - val_accuracy: 0.9143\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 18ms/step - loss: 0.2577 - accuracy: 0.9550 - val_loss: 0.5382 - val_accuracy: 0.9364\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 13ms/step - loss: 0.3028 - accuracy: 0.9545 - val_loss: 0.6313 - val_accuracy: 0.9292\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 15ms/step - loss: 0.0805 - accuracy: 0.9792 - val_loss: 0.0782 - val_accuracy: 0.9801\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.0803 - val_accuracy: 0.9812\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.3544 - accuracy: 0.9416 - val_loss: 0.3131 - val_accuracy: 0.9391\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.2159 - accuracy: 0.9549 - val_loss: 0.5523 - val_accuracy: 0.9324\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.3587 - accuracy: 0.9459 - val_loss: 0.4900 - val_accuracy: 0.9329\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 0.2561 - accuracy: 0.9573 - val_loss: 1.1978 - val_accuracy: 0.8889\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.3193 - accuracy: 0.9395 - val_loss: 0.4688 - val_accuracy: 0.9302\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.3223 - accuracy: 0.9459 - val_loss: 0.3991 - val_accuracy: 0.9286\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.0461 - accuracy: 0.9890 - val_loss: 0.0874 - val_accuracy: 0.9796\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.0917 - val_accuracy: 0.9802\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9770\n",
            "---------7------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.2001 - accuracy: 0.9637 - val_loss: 0.2418 - val_accuracy: 0.9542\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 14ms/step - loss: 0.2056 - accuracy: 0.9618 - val_loss: 0.3695 - val_accuracy: 0.9423\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 3s 21ms/step - loss: 0.0940 - accuracy: 0.9796 - val_loss: 0.0916 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.0454 - accuracy: 0.9895 - val_loss: 0.0917 - val_accuracy: 0.9778\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 19ms/step - loss: 0.0985 - accuracy: 0.9784 - val_loss: 0.0940 - val_accuracy: 0.9777\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 14ms/step - loss: 0.0432 - accuracy: 0.9882 - val_loss: 0.0930 - val_accuracy: 0.9777\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.2316 - accuracy: 0.9604 - val_loss: 0.3098 - val_accuracy: 0.9305\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.3798 - accuracy: 0.9444 - val_loss: 0.7421 - val_accuracy: 0.9215\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.1872 - accuracy: 0.9687 - val_loss: 0.4726 - val_accuracy: 0.9435\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.3405 - accuracy: 0.9596 - val_loss: 0.8747 - val_accuracy: 0.9411\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.1649 - accuracy: 0.9695 - val_loss: 0.4167 - val_accuracy: 0.9592\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.3018 - accuracy: 0.9588 - val_loss: 0.7041 - val_accuracy: 0.9362\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.0928 - accuracy: 0.9791 - val_loss: 0.0923 - val_accuracy: 0.9783\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 15ms/step - loss: 0.0779 - accuracy: 0.9816 - val_loss: 0.0908 - val_accuracy: 0.9798\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 2s 12ms/step - loss: 0.0855 - accuracy: 0.9794 - val_loss: 0.0921 - val_accuracy: 0.9793\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.0722 - accuracy: 0.9828 - val_loss: 0.0905 - val_accuracy: 0.9792\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.2062 - accuracy: 0.9599 - val_loss: 0.3818 - val_accuracy: 0.9406\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.2057 - accuracy: 0.9650 - val_loss: 0.6271 - val_accuracy: 0.9262\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.0892 - accuracy: 0.9808 - val_loss: 0.0952 - val_accuracy: 0.9771\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.0332 - accuracy: 0.9910 - val_loss: 0.0953 - val_accuracy: 0.9783\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 3s 21ms/step - loss: 0.0922 - accuracy: 0.9797 - val_loss: 0.0967 - val_accuracy: 0.9780\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.0959 - val_accuracy: 0.9796\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2293 - accuracy: 0.9629 - val_loss: 1.1269 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.3675 - accuracy: 0.9550 - val_loss: 0.3221 - val_accuracy: 0.9512\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2144 - accuracy: 0.9627 - val_loss: 0.6773 - val_accuracy: 0.9281\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.2629 - accuracy: 0.9618 - val_loss: 0.8221 - val_accuracy: 0.9410\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 2s 13ms/step - loss: 0.2121 - accuracy: 0.9640 - val_loss: 0.7364 - val_accuracy: 0.9170\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.4370 - accuracy: 0.9522 - val_loss: 0.8566 - val_accuracy: 0.9353\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 18ms/step - loss: 0.4375 - accuracy: 0.9378 - val_loss: 0.6553 - val_accuracy: 0.8941\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.3763 - accuracy: 0.9472 - val_loss: 0.7493 - val_accuracy: 0.9228\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.0584 - accuracy: 0.9837 - val_loss: 0.0937 - val_accuracy: 0.9785\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 0.0493 - accuracy: 0.9862 - val_loss: 0.0931 - val_accuracy: 0.9790\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 15ms/step - loss: 0.0563 - accuracy: 0.9847 - val_loss: 0.0914 - val_accuracy: 0.9808\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 11ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0941 - val_accuracy: 0.9804\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.0655 - accuracy: 0.9835 - val_loss: 0.0930 - val_accuracy: 0.9771\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.0910 - val_accuracy: 0.9780\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 2s 13ms/step - loss: 0.1050 - accuracy: 0.9785 - val_loss: 0.0861 - val_accuracy: 0.9795\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 12ms/step - loss: 0.0452 - accuracy: 0.9890 - val_loss: 0.0900 - val_accuracy: 0.9793\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 20ms/step - loss: 0.1323 - accuracy: 0.9754 - val_loss: 0.0808 - val_accuracy: 0.9784\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 14ms/step - loss: 0.0585 - accuracy: 0.9854 - val_loss: 0.0842 - val_accuracy: 0.9810\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 2s 13ms/step - loss: 0.1677 - accuracy: 0.9694 - val_loss: 0.4149 - val_accuracy: 0.9538\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 12ms/step - loss: 0.2761 - accuracy: 0.9627 - val_loss: 0.6546 - val_accuracy: 0.9310\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 19ms/step - loss: 0.0477 - accuracy: 0.9889 - val_loss: 0.0933 - val_accuracy: 0.9798\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.1007 - val_accuracy: 0.9796\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.1892 - accuracy: 0.9671 - val_loss: 0.4871 - val_accuracy: 0.9540\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 20ms/step - loss: 0.3860 - accuracy: 0.9581 - val_loss: 1.5268 - val_accuracy: 0.9118\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.2003 - accuracy: 0.9658 - val_loss: 0.4247 - val_accuracy: 0.9262\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.2691 - accuracy: 0.9552 - val_loss: 0.8000 - val_accuracy: 0.9296\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 18ms/step - loss: 0.2321 - accuracy: 0.9617 - val_loss: 0.3178 - val_accuracy: 0.9485\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 13ms/step - loss: 0.2600 - accuracy: 0.9596 - val_loss: 0.6503 - val_accuracy: 0.9387\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 15ms/step - loss: 0.0829 - accuracy: 0.9813 - val_loss: 0.0852 - val_accuracy: 0.9807\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 14ms/step - loss: 0.0280 - accuracy: 0.9926 - val_loss: 0.0874 - val_accuracy: 0.9816\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 11ms/step - loss: 0.4436 - accuracy: 0.9450 - val_loss: 0.6034 - val_accuracy: 0.9212\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 13ms/step - loss: 0.2520 - accuracy: 0.9591 - val_loss: 0.5650 - val_accuracy: 0.9335\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 15ms/step - loss: 0.3205 - accuracy: 0.9509 - val_loss: 0.8595 - val_accuracy: 0.9234\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 0.6300 - accuracy: 0.9352 - val_loss: 1.0282 - val_accuracy: 0.9349\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.2638 - accuracy: 0.9513 - val_loss: 1.2854 - val_accuracy: 0.8796\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 13ms/step - loss: 0.2964 - accuracy: 0.9554 - val_loss: 0.5070 - val_accuracy: 0.9312\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.0432 - accuracy: 0.9884 - val_loss: 0.0981 - val_accuracy: 0.9790\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 11ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.1027 - val_accuracy: 0.9802\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9780\n",
            "---------8------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 2s 13ms/step - loss: 0.2303 - accuracy: 0.9595 - val_loss: 0.6580 - val_accuracy: 0.9279\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.3277 - accuracy: 0.9562 - val_loss: 0.6020 - val_accuracy: 0.9328\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 21ms/step - loss: 0.0945 - accuracy: 0.9815 - val_loss: 0.0955 - val_accuracy: 0.9794\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.0926 - val_accuracy: 0.9790\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 19ms/step - loss: 0.0998 - accuracy: 0.9779 - val_loss: 0.0966 - val_accuracy: 0.9789\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.0387 - accuracy: 0.9899 - val_loss: 0.0984 - val_accuracy: 0.9787\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.1554 - accuracy: 0.9705 - val_loss: 0.2510 - val_accuracy: 0.9577\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.1886 - accuracy: 0.9660 - val_loss: 0.3436 - val_accuracy: 0.9624\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.2159 - accuracy: 0.9690 - val_loss: 1.1755 - val_accuracy: 0.9162\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.3431 - accuracy: 0.9655 - val_loss: 1.0436 - val_accuracy: 0.9333\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.1511 - accuracy: 0.9725 - val_loss: 0.5415 - val_accuracy: 0.9466\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.3045 - accuracy: 0.9650 - val_loss: 0.8061 - val_accuracy: 0.9432\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.0939 - accuracy: 0.9814 - val_loss: 0.1010 - val_accuracy: 0.9792\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 0.0796 - accuracy: 0.9829 - val_loss: 0.0992 - val_accuracy: 0.9799\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 15ms/step - loss: 0.0862 - accuracy: 0.9798 - val_loss: 0.0997 - val_accuracy: 0.9791\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.0721 - accuracy: 0.9824 - val_loss: 0.0970 - val_accuracy: 0.9795\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.2451 - accuracy: 0.9593 - val_loss: 0.6918 - val_accuracy: 0.9328\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.3616 - accuracy: 0.9546 - val_loss: 0.8675 - val_accuracy: 0.9266\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.0948 - accuracy: 0.9808 - val_loss: 0.0937 - val_accuracy: 0.9783\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.0363 - accuracy: 0.9891 - val_loss: 0.1004 - val_accuracy: 0.9785\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.0951 - accuracy: 0.9790 - val_loss: 0.1005 - val_accuracy: 0.9784\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.0993 - val_accuracy: 0.9793\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 15ms/step - loss: 0.3246 - accuracy: 0.9559 - val_loss: 0.7810 - val_accuracy: 0.9285\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 14ms/step - loss: 0.5346 - accuracy: 0.9463 - val_loss: 0.8697 - val_accuracy: 0.9358\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 4s 18ms/step - loss: 0.1871 - accuracy: 0.9670 - val_loss: 0.4097 - val_accuracy: 0.9336\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.3934 - accuracy: 0.9542 - val_loss: 0.8415 - val_accuracy: 0.9161\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 17ms/step - loss: 0.2602 - accuracy: 0.9607 - val_loss: 0.5008 - val_accuracy: 0.9326\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.3220 - accuracy: 0.9573 - val_loss: 0.7996 - val_accuracy: 0.9266\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 18ms/step - loss: 0.2127 - accuracy: 0.9626 - val_loss: 0.4822 - val_accuracy: 0.9340\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 12ms/step - loss: 0.1766 - accuracy: 0.9687 - val_loss: 0.3429 - val_accuracy: 0.9554\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.0565 - accuracy: 0.9854 - val_loss: 0.1019 - val_accuracy: 0.9786\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.0480 - accuracy: 0.9881 - val_loss: 0.1001 - val_accuracy: 0.9789\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 15ms/step - loss: 0.0556 - accuracy: 0.9862 - val_loss: 0.0974 - val_accuracy: 0.9813\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0973 - val_accuracy: 0.9809\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.0603 - accuracy: 0.9853 - val_loss: 0.0974 - val_accuracy: 0.9791\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0964 - val_accuracy: 0.9789\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 17ms/step - loss: 0.1080 - accuracy: 0.9811 - val_loss: 0.0959 - val_accuracy: 0.9804\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 12ms/step - loss: 0.0521 - accuracy: 0.9890 - val_loss: 0.0944 - val_accuracy: 0.9789\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 21ms/step - loss: 0.1363 - accuracy: 0.9757 - val_loss: 0.0867 - val_accuracy: 0.9796\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.0642 - accuracy: 0.9854 - val_loss: 0.0878 - val_accuracy: 0.9803\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.2210 - accuracy: 0.9631 - val_loss: 0.4889 - val_accuracy: 0.9390\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.3770 - accuracy: 0.9519 - val_loss: 1.1551 - val_accuracy: 0.8948\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 19ms/step - loss: 0.0432 - accuracy: 0.9911 - val_loss: 0.1156 - val_accuracy: 0.9807\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.1089 - val_accuracy: 0.9813\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.1175 - accuracy: 0.9781 - val_loss: 0.2271 - val_accuracy: 0.9672\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 15ms/step - loss: 0.1427 - accuracy: 0.9744 - val_loss: 0.5487 - val_accuracy: 0.9518\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.2775 - accuracy: 0.9617 - val_loss: 0.8224 - val_accuracy: 0.9070\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.4163 - accuracy: 0.9522 - val_loss: 0.9364 - val_accuracy: 0.9219\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 18ms/step - loss: 0.1856 - accuracy: 0.9663 - val_loss: 0.6897 - val_accuracy: 0.9163\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.3432 - accuracy: 0.9538 - val_loss: 0.6869 - val_accuracy: 0.9455\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 15ms/step - loss: 0.0845 - accuracy: 0.9810 - val_loss: 0.0943 - val_accuracy: 0.9816\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.0352 - accuracy: 0.9909 - val_loss: 0.0955 - val_accuracy: 0.9807\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 11ms/step - loss: 0.3395 - accuracy: 0.9518 - val_loss: 0.5192 - val_accuracy: 0.9304\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.3284 - accuracy: 0.9535 - val_loss: 0.8234 - val_accuracy: 0.9352\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 15ms/step - loss: 0.1798 - accuracy: 0.9663 - val_loss: 0.3328 - val_accuracy: 0.9618\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.1505 - accuracy: 0.9731 - val_loss: 0.3432 - val_accuracy: 0.9525\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.3324 - accuracy: 0.9507 - val_loss: 0.6483 - val_accuracy: 0.9165\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.5370 - accuracy: 0.9413 - val_loss: 1.0575 - val_accuracy: 0.9133\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.0377 - accuracy: 0.9914 - val_loss: 0.1022 - val_accuracy: 0.9818\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.1072 - val_accuracy: 0.9816\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1087 - accuracy: 0.9780\n",
            "---------9------------\n",
            "[0. 0. 0.]\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.2417 - accuracy: 0.9612 - val_loss: 0.2631 - val_accuracy: 0.9494\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 14ms/step - loss: 0.1580 - accuracy: 0.9685 - val_loss: 0.4576 - val_accuracy: 0.9330\n",
            "[1. 0. 0.]\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 3s 21ms/step - loss: 0.0952 - accuracy: 0.9828 - val_loss: 0.1038 - val_accuracy: 0.9801\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.0441 - accuracy: 0.9914 - val_loss: 0.1025 - val_accuracy: 0.9790\n",
            "[1. 1. 0.]\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 15ms/step - loss: 0.1021 - accuracy: 0.9776 - val_loss: 0.1035 - val_accuracy: 0.9779\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 0.1085 - val_accuracy: 0.9798\n",
            "[1. 2. 0.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.1473 - accuracy: 0.9702 - val_loss: 0.5372 - val_accuracy: 0.9363\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.2087 - accuracy: 0.9656 - val_loss: 0.7036 - val_accuracy: 0.9246\n",
            "[2. 2. 0.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.1062 - accuracy: 0.9794 - val_loss: 0.5147 - val_accuracy: 0.9516\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1078 - accuracy: 0.9826 - val_loss: 0.5865 - val_accuracy: 0.9564\n",
            "[3. 2. 0.]\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.1676 - accuracy: 0.9751 - val_loss: 0.4430 - val_accuracy: 0.9568\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.3840 - accuracy: 0.9658 - val_loss: 0.9548 - val_accuracy: 0.9365\n",
            "[4. 2. 0.]\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 17ms/step - loss: 0.0975 - accuracy: 0.9804 - val_loss: 0.1065 - val_accuracy: 0.9790\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 15ms/step - loss: 0.0848 - accuracy: 0.9827 - val_loss: 0.1051 - val_accuracy: 0.9798\n",
            "[4. 2. 1.]\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 15ms/step - loss: 0.0872 - accuracy: 0.9817 - val_loss: 0.1061 - val_accuracy: 0.9786\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.0741 - accuracy: 0.9835 - val_loss: 0.1047 - val_accuracy: 0.9788\n",
            "[4. 2. 2.]\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.1617 - accuracy: 0.9728 - val_loss: 0.4332 - val_accuracy: 0.9453\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.2001 - accuracy: 0.9731 - val_loss: 0.3829 - val_accuracy: 0.9570\n",
            "[5. 2. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.0999 - accuracy: 0.9823 - val_loss: 0.0959 - val_accuracy: 0.9798\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.0352 - accuracy: 0.9912 - val_loss: 0.1047 - val_accuracy: 0.9805\n",
            "[5. 3. 2.]\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 3s 21ms/step - loss: 0.0962 - accuracy: 0.9760 - val_loss: 0.1072 - val_accuracy: 0.9786\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 0.1098 - val_accuracy: 0.9786\n",
            "[5. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 15ms/step - loss: 0.2804 - accuracy: 0.9614 - val_loss: 0.7956 - val_accuracy: 0.9429\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.5034 - accuracy: 0.9544 - val_loss: 1.0243 - val_accuracy: 0.9429\n",
            "[6. 4. 2.]\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 15ms/step - loss: 0.2895 - accuracy: 0.9638 - val_loss: 0.9144 - val_accuracy: 0.9254\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.5327 - accuracy: 0.9539 - val_loss: 0.7242 - val_accuracy: 0.9392\n",
            "[7. 4. 2.]\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 17ms/step - loss: 0.1400 - accuracy: 0.9771 - val_loss: 0.4229 - val_accuracy: 0.9521\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.3333 - accuracy: 0.9614 - val_loss: 0.7467 - val_accuracy: 0.9556\n",
            "[8. 4. 2.]\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 22ms/step - loss: 0.2010 - accuracy: 0.9656 - val_loss: 0.3434 - val_accuracy: 0.9594\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.2036 - accuracy: 0.9727 - val_loss: 0.5935 - val_accuracy: 0.9324\n",
            "[9. 4. 2.]\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 18ms/step - loss: 0.0512 - accuracy: 0.9876 - val_loss: 0.1078 - val_accuracy: 0.9788\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 0.0439 - accuracy: 0.9889 - val_loss: 0.1069 - val_accuracy: 0.9798\n",
            "[9. 4. 3.]\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 15ms/step - loss: 0.0511 - accuracy: 0.9870 - val_loss: 0.1077 - val_accuracy: 0.9819\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.1042 - val_accuracy: 0.9804\n",
            "[9. 5. 3.]\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.0587 - accuracy: 0.9865 - val_loss: 0.1010 - val_accuracy: 0.9810\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.1019 - val_accuracy: 0.9806\n",
            "[9. 6. 3.]\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 17ms/step - loss: 0.1121 - accuracy: 0.9809 - val_loss: 0.0984 - val_accuracy: 0.9800\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.0537 - accuracy: 0.9876 - val_loss: 0.0964 - val_accuracy: 0.9795\n",
            "[9. 7. 3.]\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 20ms/step - loss: 0.1447 - accuracy: 0.9769 - val_loss: 0.0969 - val_accuracy: 0.9803\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.0811 - accuracy: 0.9841 - val_loss: 0.0953 - val_accuracy: 0.9801\n",
            "[9. 8. 3.]\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.2383 - accuracy: 0.9631 - val_loss: 0.7183 - val_accuracy: 0.9360\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 15ms/step - loss: 0.3173 - accuracy: 0.9644 - val_loss: 0.8523 - val_accuracy: 0.9300\n",
            "[10.  8.  3.]\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.0423 - accuracy: 0.9906 - val_loss: 0.1219 - val_accuracy: 0.9816\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.1245 - val_accuracy: 0.9808\n",
            "[10.  9.  3.]\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 3s 22ms/step - loss: 0.1136 - accuracy: 0.9774 - val_loss: 0.3261 - val_accuracy: 0.9588\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 15ms/step - loss: 0.2649 - accuracy: 0.9704 - val_loss: 0.9579 - val_accuracy: 0.9412\n",
            "[11.  9.  3.]\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.2467 - accuracy: 0.9638 - val_loss: 0.8088 - val_accuracy: 0.9335\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.2814 - accuracy: 0.9587 - val_loss: 0.7083 - val_accuracy: 0.9366\n",
            "[12.  9.  3.]\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 18ms/step - loss: 0.1993 - accuracy: 0.9683 - val_loss: 0.3777 - val_accuracy: 0.9577\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.2255 - accuracy: 0.9709 - val_loss: 0.7291 - val_accuracy: 0.9306\n",
            "[13.  9.  3.]\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 15ms/step - loss: 0.0861 - accuracy: 0.9819 - val_loss: 0.1010 - val_accuracy: 0.9818\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 14ms/step - loss: 0.0361 - accuracy: 0.9907 - val_loss: 0.0988 - val_accuracy: 0.9820\n",
            "[13. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.2301 - accuracy: 0.9610 - val_loss: 0.4042 - val_accuracy: 0.9479\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 13ms/step - loss: 0.2204 - accuracy: 0.9639 - val_loss: 0.4813 - val_accuracy: 0.9545\n",
            "[14. 10.  3.]\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 15ms/step - loss: 0.1997 - accuracy: 0.9663 - val_loss: 0.3835 - val_accuracy: 0.9603\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.2791 - accuracy: 0.9623 - val_loss: 0.7655 - val_accuracy: 0.9198\n",
            "[15. 10.  3.]\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.2310 - accuracy: 0.9598 - val_loss: 0.2616 - val_accuracy: 0.9491\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.1352 - accuracy: 0.9744 - val_loss: 0.2837 - val_accuracy: 0.9551\n",
            "[16. 10.  3.]\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 16ms/step - loss: 0.0348 - accuracy: 0.9935 - val_loss: 0.1107 - val_accuracy: 0.9818\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 12ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.1161 - val_accuracy: 0.9825\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1145 - accuracy: 0.9806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "J5gvkkJF81zS",
        "outputId": "d29ebbc1-48dc-449a-b05e-f67ce566f9df"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot(serverhist1['accuracy'], label=\"loss\")\n",
        "ax.legend()\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot(serverhist1['loss'], label=\"accuracy\")\n",
        "ax.legend()\n",
        "plt.savefig(\"Clustered Genetic FL\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5gGXFwoXzCC",
        "outputId": "6e7d0d43-1209-415f-e4ee-895b49e07df3"
      },
      "source": [
        "losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4576,\n",
              " 0.1025,\n",
              " 0.1085,\n",
              " 0.7036,\n",
              " 0.5865,\n",
              " 0.9548,\n",
              " 0.1051,\n",
              " 0.1047,\n",
              " 0.3829,\n",
              " 0.1047,\n",
              " 0.1098,\n",
              " 1.0243,\n",
              " 0.7242,\n",
              " 0.7467,\n",
              " 0.5935,\n",
              " 0.1069,\n",
              " 0.1042,\n",
              " 0.1019,\n",
              " 0.0964,\n",
              " 0.0953,\n",
              " 0.8523,\n",
              " 0.1245,\n",
              " 0.9579,\n",
              " 0.7083,\n",
              " 0.7291,\n",
              " 0.0988,\n",
              " 0.4813,\n",
              " 0.7655,\n",
              " 0.2837,\n",
              " 0.1161]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQAr-G-MXF0D",
        "outputId": "ffd119a0-376f-43b3-8560-26a07b45d2ad"
      },
      "source": [
        "server_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11451054364442825, 0.9805999994277954]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp-SXeCW6DrV"
      },
      "source": [
        "# Generic FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhCR65NEqD11",
        "outputId": "55e87b39-c083-4f6c-df0d-97e1e52421a8"
      },
      "source": [
        "client_models = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "server_model_norm = create_server_model()\n",
        "server_model_norm.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "serverhist={\n",
        "    \"loss\":[],\n",
        "    \"accuracy\":[]\n",
        "}\n",
        "\n",
        "for i in range(NUM_ROUNDS):\n",
        "  print(\"-----\"+str(i)+\"---------\")\n",
        "  losses = []\n",
        "  lr_init = []\n",
        "  data= []\n",
        "  for j in range(NUM_CLIENTS):\n",
        "    data.append(train_client(j, server_model_norm, 0.0001))\n",
        "\n",
        "    client_models[j] = data[j][0]\n",
        "    losses.append(data[j][2])\n",
        "    lr_init.append(data[j][1])\n",
        "\n",
        "  # Aggregating model\n",
        "  sum=[i*0 for i in client_models[0].get_weights()]\n",
        "  for i in range(NUM_CLIENTS):\n",
        "    sum = [i+j for i, j in zip(client_models[i].get_weights(), sum)]\n",
        "  server_model_norm.set_weights([i/NUM_CLIENTS for i in sum])\n",
        "  h=server_model_norm.evaluate(X_test,y_test)\n",
        "  serverhist['loss'].append(h[1])\n",
        "  serverhist['accuracy'].append(h[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----0---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 1.2784 - accuracy: 0.7355 - val_loss: 0.6644 - val_accuracy: 0.8459\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5199 - accuracy: 0.8713 - val_loss: 0.4327 - val_accuracy: 0.8860\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 1.5492 - accuracy: 0.6710 - val_loss: 0.8974 - val_accuracy: 0.8350\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 14ms/step - loss: 0.6766 - accuracy: 0.8543 - val_loss: 0.5298 - val_accuracy: 0.8770\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 18ms/step - loss: 1.4498 - accuracy: 0.6814 - val_loss: 0.8364 - val_accuracy: 0.8311\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 16ms/step - loss: 0.6127 - accuracy: 0.8620 - val_loss: 0.5023 - val_accuracy: 0.8775\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 1.5654 - accuracy: 0.6535 - val_loss: 0.9187 - val_accuracy: 0.8174\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.7084 - accuracy: 0.8436 - val_loss: 0.5441 - val_accuracy: 0.8752\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.4696 - accuracy: 0.6895 - val_loss: 0.8436 - val_accuracy: 0.8231\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.6186 - accuracy: 0.8649 - val_loss: 0.5180 - val_accuracy: 0.8796\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 1.4187 - accuracy: 0.6972 - val_loss: 0.7845 - val_accuracy: 0.8541\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.5894 - accuracy: 0.8649 - val_loss: 0.4816 - val_accuracy: 0.8861\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 2s 13ms/step - loss: 1.3089 - accuracy: 0.7133 - val_loss: 0.7067 - val_accuracy: 0.8518\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 11ms/step - loss: 0.5236 - accuracy: 0.8770 - val_loss: 0.4502 - val_accuracy: 0.8844\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 1.2193 - accuracy: 0.7476 - val_loss: 0.5843 - val_accuracy: 0.8695\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 12ms/step - loss: 0.4793 - accuracy: 0.8818 - val_loss: 0.3920 - val_accuracy: 0.9018\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 1.4737 - accuracy: 0.6801 - val_loss: 0.8472 - val_accuracy: 0.8468\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.6290 - accuracy: 0.8628 - val_loss: 0.5137 - val_accuracy: 0.8773\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 1.1899 - accuracy: 0.7483 - val_loss: 0.6000 - val_accuracy: 0.8540\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.4609 - accuracy: 0.8902 - val_loss: 0.4035 - val_accuracy: 0.8972\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 1.5887 - accuracy: 0.6611 - val_loss: 0.9606 - val_accuracy: 0.8068\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.7220 - accuracy: 0.8432 - val_loss: 0.5632 - val_accuracy: 0.8680\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 1.2403 - accuracy: 0.7158 - val_loss: 0.5907 - val_accuracy: 0.8714\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.5058 - accuracy: 0.8716 - val_loss: 0.3875 - val_accuracy: 0.9025\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 1.1945 - accuracy: 0.7565 - val_loss: 0.6001 - val_accuracy: 0.8631\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.4581 - accuracy: 0.8843 - val_loss: 0.3991 - val_accuracy: 0.8983\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 1.3594 - accuracy: 0.6908 - val_loss: 0.6761 - val_accuracy: 0.8625\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.5589 - accuracy: 0.8681 - val_loss: 0.4311 - val_accuracy: 0.8897\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 1.3748 - accuracy: 0.7127 - val_loss: 0.7605 - val_accuracy: 0.8241\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.5656 - accuracy: 0.8651 - val_loss: 0.4612 - val_accuracy: 0.8834\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 19ms/step - loss: 1.3629 - accuracy: 0.6980 - val_loss: 0.7221 - val_accuracy: 0.8465\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.5519 - accuracy: 0.8663 - val_loss: 0.4510 - val_accuracy: 0.8825\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 1.2037 - accuracy: 0.7287 - val_loss: 0.5976 - val_accuracy: 0.8593\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.4733 - accuracy: 0.8771 - val_loss: 0.4002 - val_accuracy: 0.8921\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 1.3482 - accuracy: 0.7186 - val_loss: 0.7042 - val_accuracy: 0.8532\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 0.5477 - accuracy: 0.8667 - val_loss: 0.4474 - val_accuracy: 0.8861\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 1.3297 - accuracy: 0.7233 - val_loss: 0.7036 - val_accuracy: 0.8527\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 1s 11ms/step - loss: 0.5201 - accuracy: 0.8763 - val_loss: 0.4404 - val_accuracy: 0.8919\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 1.6041 - accuracy: 0.6569 - val_loss: 0.8965 - val_accuracy: 0.8408\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 17ms/step - loss: 0.7534 - accuracy: 0.8330 - val_loss: 0.5228 - val_accuracy: 0.8839\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 1.2825 - accuracy: 0.7317 - val_loss: 0.6627 - val_accuracy: 0.8606\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 14ms/step - loss: 0.5096 - accuracy: 0.8794 - val_loss: 0.4360 - val_accuracy: 0.8918\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 1.4311 - accuracy: 0.6896 - val_loss: 0.8008 - val_accuracy: 0.8428\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.5984 - accuracy: 0.8711 - val_loss: 0.4932 - val_accuracy: 0.8829\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 20ms/step - loss: 1.5818 - accuracy: 0.6544 - val_loss: 0.9218 - val_accuracy: 0.8347\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 14ms/step - loss: 0.7187 - accuracy: 0.8475 - val_loss: 0.5425 - val_accuracy: 0.8760\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 1.4845 - accuracy: 0.6932 - val_loss: 0.8493 - val_accuracy: 0.8189\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.6470 - accuracy: 0.8479 - val_loss: 0.5132 - val_accuracy: 0.8790\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 1.4115 - accuracy: 0.7085 - val_loss: 0.7564 - val_accuracy: 0.8501\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.5734 - accuracy: 0.8712 - val_loss: 0.4578 - val_accuracy: 0.8864\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 1.2291 - accuracy: 0.7251 - val_loss: 0.6065 - val_accuracy: 0.8626\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.4984 - accuracy: 0.8732 - val_loss: 0.4004 - val_accuracy: 0.8952\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 1.1509 - accuracy: 0.7503 - val_loss: 0.5536 - val_accuracy: 0.8700\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.4371 - accuracy: 0.8867 - val_loss: 0.3788 - val_accuracy: 0.9008\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 1.2272 - accuracy: 0.7393 - val_loss: 0.6072 - val_accuracy: 0.8670\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 0.4995 - accuracy: 0.8757 - val_loss: 0.4123 - val_accuracy: 0.8926\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 1.1671 - accuracy: 0.7507 - val_loss: 0.5633 - val_accuracy: 0.8632\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.4586 - accuracy: 0.8779 - val_loss: 0.3886 - val_accuracy: 0.8975\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 1.3044 - accuracy: 0.7168 - val_loss: 0.6383 - val_accuracy: 0.8627\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 10ms/step - loss: 0.5167 - accuracy: 0.8781 - val_loss: 0.4109 - val_accuracy: 0.8973\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4395 - accuracy: 0.8964\n",
            "-----1---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 14ms/step - loss: 0.4106 - accuracy: 0.8899 - val_loss: 0.3524 - val_accuracy: 0.9041\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 13ms/step - loss: 0.3341 - accuracy: 0.9105 - val_loss: 0.3170 - val_accuracy: 0.9119\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.4198 - accuracy: 0.8827 - val_loss: 0.3672 - val_accuracy: 0.9031\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 13ms/step - loss: 0.3379 - accuracy: 0.9069 - val_loss: 0.3364 - val_accuracy: 0.9046\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 18ms/step - loss: 0.4057 - accuracy: 0.8967 - val_loss: 0.3656 - val_accuracy: 0.9053\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 1s 12ms/step - loss: 0.3245 - accuracy: 0.9152 - val_loss: 0.3356 - val_accuracy: 0.9062\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.4390 - accuracy: 0.8819 - val_loss: 0.3715 - val_accuracy: 0.9035\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.3599 - accuracy: 0.8989 - val_loss: 0.3381 - val_accuracy: 0.9084\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.3966 - accuracy: 0.8953 - val_loss: 0.3869 - val_accuracy: 0.8977\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.3115 - accuracy: 0.9162 - val_loss: 0.3417 - val_accuracy: 0.9078\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.4108 - accuracy: 0.8874 - val_loss: 0.3647 - val_accuracy: 0.9055\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.3265 - accuracy: 0.9128 - val_loss: 0.3333 - val_accuracy: 0.9076\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 0.4003 - accuracy: 0.8961 - val_loss: 0.3603 - val_accuracy: 0.9018\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 1s 11ms/step - loss: 0.3230 - accuracy: 0.9090 - val_loss: 0.3295 - val_accuracy: 0.9087\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.4107 - accuracy: 0.8886 - val_loss: 0.3452 - val_accuracy: 0.9109\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 12ms/step - loss: 0.3232 - accuracy: 0.9116 - val_loss: 0.3184 - val_accuracy: 0.9097\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.4062 - accuracy: 0.8924 - val_loss: 0.3800 - val_accuracy: 0.8960\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.3304 - accuracy: 0.9118 - val_loss: 0.3437 - val_accuracy: 0.9032\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.3874 - accuracy: 0.8979 - val_loss: 0.3567 - val_accuracy: 0.9022\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.3072 - accuracy: 0.9176 - val_loss: 0.3083 - val_accuracy: 0.9152\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.4395 - accuracy: 0.8839 - val_loss: 0.3959 - val_accuracy: 0.8955\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.3558 - accuracy: 0.9042 - val_loss: 0.3421 - val_accuracy: 0.9061\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.4381 - accuracy: 0.8786 - val_loss: 0.3412 - val_accuracy: 0.9078\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.3468 - accuracy: 0.9040 - val_loss: 0.3021 - val_accuracy: 0.9161\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 13ms/step - loss: 0.3832 - accuracy: 0.9006 - val_loss: 0.3491 - val_accuracy: 0.9086\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.2998 - accuracy: 0.9172 - val_loss: 0.3147 - val_accuracy: 0.9137\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 19ms/step - loss: 0.4370 - accuracy: 0.8845 - val_loss: 0.3530 - val_accuracy: 0.9030\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.3446 - accuracy: 0.9062 - val_loss: 0.3135 - val_accuracy: 0.9140\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.4134 - accuracy: 0.8876 - val_loss: 0.3611 - val_accuracy: 0.8997\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.3418 - accuracy: 0.9042 - val_loss: 0.3247 - val_accuracy: 0.9077\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 16ms/step - loss: 0.4093 - accuracy: 0.8920 - val_loss: 0.3600 - val_accuracy: 0.9065\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 1s 12ms/step - loss: 0.3354 - accuracy: 0.9071 - val_loss: 0.3176 - val_accuracy: 0.9100\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.4063 - accuracy: 0.8909 - val_loss: 0.3443 - val_accuracy: 0.8998\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.3284 - accuracy: 0.9077 - val_loss: 0.3147 - val_accuracy: 0.9094\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 0.4110 - accuracy: 0.8898 - val_loss: 0.3705 - val_accuracy: 0.8984\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 0.3293 - accuracy: 0.9091 - val_loss: 0.3316 - val_accuracy: 0.9086\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.3916 - accuracy: 0.9001 - val_loss: 0.3589 - val_accuracy: 0.9025\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 14ms/step - loss: 0.3141 - accuracy: 0.9148 - val_loss: 0.3144 - val_accuracy: 0.9116\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.4906 - accuracy: 0.8694 - val_loss: 0.3700 - val_accuracy: 0.9058\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 14ms/step - loss: 0.3976 - accuracy: 0.8931 - val_loss: 0.3301 - val_accuracy: 0.9109\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.4017 - accuracy: 0.8950 - val_loss: 0.3553 - val_accuracy: 0.9053\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 14ms/step - loss: 0.3132 - accuracy: 0.9163 - val_loss: 0.3348 - val_accuracy: 0.9107\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 18ms/step - loss: 0.4024 - accuracy: 0.8965 - val_loss: 0.3642 - val_accuracy: 0.9013\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.3217 - accuracy: 0.9151 - val_loss: 0.3399 - val_accuracy: 0.9065\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 20ms/step - loss: 0.4286 - accuracy: 0.8913 - val_loss: 0.3663 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 14ms/step - loss: 0.3458 - accuracy: 0.9046 - val_loss: 0.3367 - val_accuracy: 0.9101\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.4193 - accuracy: 0.8904 - val_loss: 0.3687 - val_accuracy: 0.8967\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.3485 - accuracy: 0.9053 - val_loss: 0.3314 - val_accuracy: 0.9061\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.4011 - accuracy: 0.8996 - val_loss: 0.3597 - val_accuracy: 0.9024\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.3187 - accuracy: 0.9188 - val_loss: 0.3158 - val_accuracy: 0.9119\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.4226 - accuracy: 0.8843 - val_loss: 0.3549 - val_accuracy: 0.9039\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 10ms/step - loss: 0.3399 - accuracy: 0.9056 - val_loss: 0.3104 - val_accuracy: 0.9106\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.3931 - accuracy: 0.8918 - val_loss: 0.3417 - val_accuracy: 0.9074\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.3104 - accuracy: 0.9108 - val_loss: 0.3033 - val_accuracy: 0.9154\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.4241 - accuracy: 0.8815 - val_loss: 0.3450 - val_accuracy: 0.9062\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.3412 - accuracy: 0.9073 - val_loss: 0.3074 - val_accuracy: 0.9111\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3974 - accuracy: 0.8905 - val_loss: 0.3411 - val_accuracy: 0.9050\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.3154 - accuracy: 0.9115 - val_loss: 0.3039 - val_accuracy: 0.9151\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 19ms/step - loss: 0.4083 - accuracy: 0.8916 - val_loss: 0.3477 - val_accuracy: 0.9067\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.3214 - accuracy: 0.9070 - val_loss: 0.3061 - val_accuracy: 0.9146\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3038 - accuracy: 0.9195\n",
            "-----2---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.3251 - accuracy: 0.9084 - val_loss: 0.2917 - val_accuracy: 0.9181\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 13ms/step - loss: 0.2818 - accuracy: 0.9193 - val_loss: 0.2805 - val_accuracy: 0.9193\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.3112 - accuracy: 0.9079 - val_loss: 0.2961 - val_accuracy: 0.9150\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 18ms/step - loss: 0.2749 - accuracy: 0.9225 - val_loss: 0.2855 - val_accuracy: 0.9182\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 18ms/step - loss: 0.3052 - accuracy: 0.9163 - val_loss: 0.2987 - val_accuracy: 0.9159\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 16ms/step - loss: 0.2623 - accuracy: 0.9261 - val_loss: 0.2856 - val_accuracy: 0.9203\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 20ms/step - loss: 0.3320 - accuracy: 0.9077 - val_loss: 0.2949 - val_accuracy: 0.9163\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.2924 - accuracy: 0.9182 - val_loss: 0.2931 - val_accuracy: 0.9153\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 19ms/step - loss: 0.2885 - accuracy: 0.9154 - val_loss: 0.3065 - val_accuracy: 0.9172\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.2486 - accuracy: 0.9307 - val_loss: 0.2902 - val_accuracy: 0.9214\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.3032 - accuracy: 0.9125 - val_loss: 0.3131 - val_accuracy: 0.9114\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 12ms/step - loss: 0.2581 - accuracy: 0.9273 - val_loss: 0.2821 - val_accuracy: 0.9237\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 2s 13ms/step - loss: 0.3109 - accuracy: 0.9118 - val_loss: 0.2956 - val_accuracy: 0.9157\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 11ms/step - loss: 0.2717 - accuracy: 0.9234 - val_loss: 0.3024 - val_accuracy: 0.9157\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.3141 - accuracy: 0.9114 - val_loss: 0.2856 - val_accuracy: 0.9192\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.2679 - accuracy: 0.9257 - val_loss: 0.2734 - val_accuracy: 0.9239\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.3073 - accuracy: 0.9160 - val_loss: 0.3069 - val_accuracy: 0.9105\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.2647 - accuracy: 0.9277 - val_loss: 0.2947 - val_accuracy: 0.9142\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.3016 - accuracy: 0.9143 - val_loss: 0.2917 - val_accuracy: 0.9191\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2587 - accuracy: 0.9265 - val_loss: 0.2702 - val_accuracy: 0.9228\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.3262 - accuracy: 0.9049 - val_loss: 0.3045 - val_accuracy: 0.9157\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.2837 - accuracy: 0.9183 - val_loss: 0.3099 - val_accuracy: 0.9114\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3456 - accuracy: 0.9000 - val_loss: 0.2839 - val_accuracy: 0.9201\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.2995 - accuracy: 0.9122 - val_loss: 0.2618 - val_accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2958 - accuracy: 0.9127 - val_loss: 0.2912 - val_accuracy: 0.9191\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.2532 - accuracy: 0.9255 - val_loss: 0.2767 - val_accuracy: 0.9233\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.3312 - accuracy: 0.9007 - val_loss: 0.2954 - val_accuracy: 0.9173\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.2863 - accuracy: 0.9201 - val_loss: 0.2795 - val_accuracy: 0.9189\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 0.3203 - accuracy: 0.9075 - val_loss: 0.2919 - val_accuracy: 0.9190\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 15ms/step - loss: 0.2821 - accuracy: 0.9199 - val_loss: 0.2847 - val_accuracy: 0.9185\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 22ms/step - loss: 0.3142 - accuracy: 0.9130 - val_loss: 0.2862 - val_accuracy: 0.9183\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.2732 - accuracy: 0.9261 - val_loss: 0.2774 - val_accuracy: 0.9210\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.3205 - accuracy: 0.9111 - val_loss: 0.2834 - val_accuracy: 0.9204\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.2815 - accuracy: 0.9189 - val_loss: 0.2708 - val_accuracy: 0.9216\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 0.3128 - accuracy: 0.9088 - val_loss: 0.3002 - val_accuracy: 0.9121\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.2726 - accuracy: 0.9237 - val_loss: 0.2785 - val_accuracy: 0.9197\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.3021 - accuracy: 0.9169 - val_loss: 0.2908 - val_accuracy: 0.9177\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.2596 - accuracy: 0.9288 - val_loss: 0.2796 - val_accuracy: 0.9189\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 15ms/step - loss: 0.3764 - accuracy: 0.8925 - val_loss: 0.3023 - val_accuracy: 0.9156\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.3225 - accuracy: 0.9006 - val_loss: 0.2897 - val_accuracy: 0.9195\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.3071 - accuracy: 0.9122 - val_loss: 0.3048 - val_accuracy: 0.9156\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 14ms/step - loss: 0.2630 - accuracy: 0.9247 - val_loss: 0.2814 - val_accuracy: 0.9215\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 18ms/step - loss: 0.3067 - accuracy: 0.9151 - val_loss: 0.3027 - val_accuracy: 0.9127\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.2655 - accuracy: 0.9275 - val_loss: 0.2923 - val_accuracy: 0.9166\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 20ms/step - loss: 0.3116 - accuracy: 0.9066 - val_loss: 0.2955 - val_accuracy: 0.9191\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 18ms/step - loss: 0.2725 - accuracy: 0.9256 - val_loss: 0.2791 - val_accuracy: 0.9237\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.3238 - accuracy: 0.9094 - val_loss: 0.3085 - val_accuracy: 0.9119\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.2872 - accuracy: 0.9201 - val_loss: 0.2874 - val_accuracy: 0.9170\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.2933 - accuracy: 0.9170 - val_loss: 0.2848 - val_accuracy: 0.9207\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.2526 - accuracy: 0.9310 - val_loss: 0.2761 - val_accuracy: 0.9219\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.3356 - accuracy: 0.9067 - val_loss: 0.2840 - val_accuracy: 0.9199\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.2907 - accuracy: 0.9197 - val_loss: 0.2626 - val_accuracy: 0.9227\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3047 - accuracy: 0.9094 - val_loss: 0.2840 - val_accuracy: 0.9197\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.2629 - accuracy: 0.9201 - val_loss: 0.2796 - val_accuracy: 0.9193\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.3356 - accuracy: 0.9048 - val_loss: 0.2996 - val_accuracy: 0.9136\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.2869 - accuracy: 0.9204 - val_loss: 0.2720 - val_accuracy: 0.9181\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.3109 - accuracy: 0.9108 - val_loss: 0.2898 - val_accuracy: 0.9193\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.2694 - accuracy: 0.9235 - val_loss: 0.2714 - val_accuracy: 0.9227\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.3114 - accuracy: 0.9072 - val_loss: 0.2944 - val_accuracy: 0.9188\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2689 - accuracy: 0.9277 - val_loss: 0.2714 - val_accuracy: 0.9227\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.9264\n",
            "-----3---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.2856 - accuracy: 0.9164 - val_loss: 0.2617 - val_accuracy: 0.9248\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.2542 - accuracy: 0.9245 - val_loss: 0.2628 - val_accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.2668 - accuracy: 0.9225 - val_loss: 0.2636 - val_accuracy: 0.9226\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 18ms/step - loss: 0.2337 - accuracy: 0.9311 - val_loss: 0.2706 - val_accuracy: 0.9159\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 2s 18ms/step - loss: 0.2654 - accuracy: 0.9278 - val_loss: 0.2651 - val_accuracy: 0.9243\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.2304 - accuracy: 0.9373 - val_loss: 0.2686 - val_accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 0.2922 - accuracy: 0.9185 - val_loss: 0.2637 - val_accuracy: 0.9242\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.2587 - accuracy: 0.9274 - val_loss: 0.2561 - val_accuracy: 0.9285\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.2504 - accuracy: 0.9245 - val_loss: 0.2675 - val_accuracy: 0.9260\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.2125 - accuracy: 0.9398 - val_loss: 0.2658 - val_accuracy: 0.9280\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.2550 - accuracy: 0.9265 - val_loss: 0.2627 - val_accuracy: 0.9258\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.2229 - accuracy: 0.9371 - val_loss: 0.2602 - val_accuracy: 0.9266\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 15ms/step - loss: 0.2746 - accuracy: 0.9227 - val_loss: 0.2754 - val_accuracy: 0.9213\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 11ms/step - loss: 0.2394 - accuracy: 0.9334 - val_loss: 0.2542 - val_accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.2784 - accuracy: 0.9196 - val_loss: 0.2685 - val_accuracy: 0.9234\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.2410 - accuracy: 0.9326 - val_loss: 0.2460 - val_accuracy: 0.9325\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.2699 - accuracy: 0.9241 - val_loss: 0.2645 - val_accuracy: 0.9261\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.2336 - accuracy: 0.9348 - val_loss: 0.2619 - val_accuracy: 0.9245\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2645 - accuracy: 0.9254 - val_loss: 0.2595 - val_accuracy: 0.9250\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.2331 - accuracy: 0.9346 - val_loss: 0.2535 - val_accuracy: 0.9275\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 0.2846 - accuracy: 0.9180 - val_loss: 0.2689 - val_accuracy: 0.9219\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 18ms/step - loss: 0.2508 - accuracy: 0.9255 - val_loss: 0.2622 - val_accuracy: 0.9263\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.3051 - accuracy: 0.9116 - val_loss: 0.2467 - val_accuracy: 0.9278\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2651 - accuracy: 0.9236 - val_loss: 0.2442 - val_accuracy: 0.9279\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.2592 - accuracy: 0.9238 - val_loss: 0.2686 - val_accuracy: 0.9224\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2257 - accuracy: 0.9360 - val_loss: 0.2474 - val_accuracy: 0.9313\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.2873 - accuracy: 0.9155 - val_loss: 0.2634 - val_accuracy: 0.9240\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.2540 - accuracy: 0.9273 - val_loss: 0.2565 - val_accuracy: 0.9266\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.2824 - accuracy: 0.9197 - val_loss: 0.2582 - val_accuracy: 0.9258\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.2504 - accuracy: 0.9257 - val_loss: 0.2528 - val_accuracy: 0.9264\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.2745 - accuracy: 0.9241 - val_loss: 0.2562 - val_accuracy: 0.9253\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.2423 - accuracy: 0.9311 - val_loss: 0.2470 - val_accuracy: 0.9283\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.2845 - accuracy: 0.9183 - val_loss: 0.2713 - val_accuracy: 0.9208\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.2514 - accuracy: 0.9300 - val_loss: 0.2461 - val_accuracy: 0.9264\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 0.2742 - accuracy: 0.9223 - val_loss: 0.2598 - val_accuracy: 0.9271\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 0.2422 - accuracy: 0.9326 - val_loss: 0.2608 - val_accuracy: 0.9244\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.2646 - accuracy: 0.9258 - val_loss: 0.2643 - val_accuracy: 0.9240\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 11ms/step - loss: 0.2332 - accuracy: 0.9353 - val_loss: 0.2514 - val_accuracy: 0.9282\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 20ms/step - loss: 0.3239 - accuracy: 0.9015 - val_loss: 0.2583 - val_accuracy: 0.9298\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.2838 - accuracy: 0.9171 - val_loss: 0.2871 - val_accuracy: 0.9160\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 15ms/step - loss: 0.2665 - accuracy: 0.9224 - val_loss: 0.2635 - val_accuracy: 0.9246\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.2309 - accuracy: 0.9332 - val_loss: 0.2784 - val_accuracy: 0.9209\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 0.2641 - accuracy: 0.9250 - val_loss: 0.2605 - val_accuracy: 0.9271\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.2363 - accuracy: 0.9347 - val_loss: 0.2587 - val_accuracy: 0.9276\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 20ms/step - loss: 0.2683 - accuracy: 0.9196 - val_loss: 0.2590 - val_accuracy: 0.9283\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 19ms/step - loss: 0.2350 - accuracy: 0.9352 - val_loss: 0.2612 - val_accuracy: 0.9263\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.2846 - accuracy: 0.9177 - val_loss: 0.2614 - val_accuracy: 0.9255\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.2545 - accuracy: 0.9234 - val_loss: 0.2558 - val_accuracy: 0.9273\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.2539 - accuracy: 0.9280 - val_loss: 0.2721 - val_accuracy: 0.9195\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.2191 - accuracy: 0.9387 - val_loss: 0.2479 - val_accuracy: 0.9244\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.2938 - accuracy: 0.9168 - val_loss: 0.2673 - val_accuracy: 0.9221\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 10ms/step - loss: 0.2588 - accuracy: 0.9261 - val_loss: 0.2413 - val_accuracy: 0.9301\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2695 - accuracy: 0.9196 - val_loss: 0.2594 - val_accuracy: 0.9239\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.2355 - accuracy: 0.9284 - val_loss: 0.2511 - val_accuracy: 0.9282\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.2994 - accuracy: 0.9125 - val_loss: 0.2573 - val_accuracy: 0.9245\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.2572 - accuracy: 0.9292 - val_loss: 0.2518 - val_accuracy: 0.9264\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 2s 11ms/step - loss: 0.2724 - accuracy: 0.9206 - val_loss: 0.2587 - val_accuracy: 0.9244\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.2399 - accuracy: 0.9312 - val_loss: 0.2479 - val_accuracy: 0.9300\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.2700 - accuracy: 0.9232 - val_loss: 0.2590 - val_accuracy: 0.9264\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2380 - accuracy: 0.9348 - val_loss: 0.2453 - val_accuracy: 0.9319\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2366 - accuracy: 0.9329\n",
            "-----4---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.2617 - accuracy: 0.9209 - val_loss: 0.2337 - val_accuracy: 0.9341\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.2342 - accuracy: 0.9312 - val_loss: 0.2379 - val_accuracy: 0.9314\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.2402 - accuracy: 0.9315 - val_loss: 0.2401 - val_accuracy: 0.9292\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 18ms/step - loss: 0.2105 - accuracy: 0.9410 - val_loss: 0.2381 - val_accuracy: 0.9296\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 18ms/step - loss: 0.2374 - accuracy: 0.9331 - val_loss: 0.2532 - val_accuracy: 0.9288\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.2103 - accuracy: 0.9418 - val_loss: 0.2343 - val_accuracy: 0.9335\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 0.2612 - accuracy: 0.9264 - val_loss: 0.2530 - val_accuracy: 0.9271\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.2336 - accuracy: 0.9365 - val_loss: 0.2344 - val_accuracy: 0.9318\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 19ms/step - loss: 0.2231 - accuracy: 0.9336 - val_loss: 0.2484 - val_accuracy: 0.9305\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.1900 - accuracy: 0.9466 - val_loss: 0.2485 - val_accuracy: 0.9315\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.2302 - accuracy: 0.9326 - val_loss: 0.2434 - val_accuracy: 0.9295\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.1992 - accuracy: 0.9409 - val_loss: 0.2374 - val_accuracy: 0.9328\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.2521 - accuracy: 0.9277 - val_loss: 0.2501 - val_accuracy: 0.9281\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 15ms/step - loss: 0.2192 - accuracy: 0.9416 - val_loss: 0.2440 - val_accuracy: 0.9287\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.2494 - accuracy: 0.9290 - val_loss: 0.2499 - val_accuracy: 0.9275\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.2186 - accuracy: 0.9372 - val_loss: 0.2280 - val_accuracy: 0.9353\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.2431 - accuracy: 0.9348 - val_loss: 0.2413 - val_accuracy: 0.9330\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.2123 - accuracy: 0.9432 - val_loss: 0.2459 - val_accuracy: 0.9271\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2416 - accuracy: 0.9283 - val_loss: 0.2375 - val_accuracy: 0.9317\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.2091 - accuracy: 0.9394 - val_loss: 0.2337 - val_accuracy: 0.9305\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.2574 - accuracy: 0.9259 - val_loss: 0.2410 - val_accuracy: 0.9337\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.2252 - accuracy: 0.9357 - val_loss: 0.2454 - val_accuracy: 0.9319\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2739 - accuracy: 0.9203 - val_loss: 0.2388 - val_accuracy: 0.9296\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2403 - accuracy: 0.9299 - val_loss: 0.2241 - val_accuracy: 0.9353\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2349 - accuracy: 0.9310 - val_loss: 0.2396 - val_accuracy: 0.9325\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2061 - accuracy: 0.9395 - val_loss: 0.2329 - val_accuracy: 0.9324\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.2587 - accuracy: 0.9242 - val_loss: 0.2343 - val_accuracy: 0.9304\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.2274 - accuracy: 0.9319 - val_loss: 0.2283 - val_accuracy: 0.9340\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.2528 - accuracy: 0.9280 - val_loss: 0.2334 - val_accuracy: 0.9328\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.2252 - accuracy: 0.9348 - val_loss: 0.2424 - val_accuracy: 0.9301\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.2491 - accuracy: 0.9281 - val_loss: 0.2398 - val_accuracy: 0.9315\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.2178 - accuracy: 0.9370 - val_loss: 0.2306 - val_accuracy: 0.9302\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.2557 - accuracy: 0.9242 - val_loss: 0.2342 - val_accuracy: 0.9292\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.2262 - accuracy: 0.9372 - val_loss: 0.2291 - val_accuracy: 0.9318\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.2523 - accuracy: 0.9281 - val_loss: 0.2464 - val_accuracy: 0.9292\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.2192 - accuracy: 0.9402 - val_loss: 0.2338 - val_accuracy: 0.9336\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.2388 - accuracy: 0.9323 - val_loss: 0.2348 - val_accuracy: 0.9332\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.2115 - accuracy: 0.9407 - val_loss: 0.2312 - val_accuracy: 0.9349\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 20ms/step - loss: 0.2924 - accuracy: 0.9112 - val_loss: 0.2492 - val_accuracy: 0.9288\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 1s 14ms/step - loss: 0.2533 - accuracy: 0.9286 - val_loss: 0.2376 - val_accuracy: 0.9315\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.2397 - accuracy: 0.9341 - val_loss: 0.2401 - val_accuracy: 0.9290\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.2084 - accuracy: 0.9406 - val_loss: 0.2339 - val_accuracy: 0.9335\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.2437 - accuracy: 0.9311 - val_loss: 0.2394 - val_accuracy: 0.9325\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.2116 - accuracy: 0.9441 - val_loss: 0.2397 - val_accuracy: 0.9300\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.2425 - accuracy: 0.9322 - val_loss: 0.2520 - val_accuracy: 0.9258\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 19ms/step - loss: 0.2103 - accuracy: 0.9395 - val_loss: 0.2349 - val_accuracy: 0.9316\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.2582 - accuracy: 0.9272 - val_loss: 0.2425 - val_accuracy: 0.9295\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 0.2277 - accuracy: 0.9382 - val_loss: 0.2367 - val_accuracy: 0.9308\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 17ms/step - loss: 0.2238 - accuracy: 0.9407 - val_loss: 0.2362 - val_accuracy: 0.9335\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.1948 - accuracy: 0.9433 - val_loss: 0.2286 - val_accuracy: 0.9320\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.2683 - accuracy: 0.9246 - val_loss: 0.2329 - val_accuracy: 0.9317\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.2351 - accuracy: 0.9341 - val_loss: 0.2313 - val_accuracy: 0.9310\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2436 - accuracy: 0.9250 - val_loss: 0.2342 - val_accuracy: 0.9322\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.2150 - accuracy: 0.9342 - val_loss: 0.2305 - val_accuracy: 0.9341\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.2690 - accuracy: 0.9221 - val_loss: 0.2430 - val_accuracy: 0.9280\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.2335 - accuracy: 0.9307 - val_loss: 0.2248 - val_accuracy: 0.9339\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2476 - accuracy: 0.9289 - val_loss: 0.2388 - val_accuracy: 0.9331\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.2180 - accuracy: 0.9366 - val_loss: 0.2278 - val_accuracy: 0.9351\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.2447 - accuracy: 0.9283 - val_loss: 0.2356 - val_accuracy: 0.9326\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2142 - accuracy: 0.9401 - val_loss: 0.2257 - val_accuracy: 0.9351\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9392\n",
            "-----5---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.2423 - accuracy: 0.9289 - val_loss: 0.2247 - val_accuracy: 0.9355\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.2140 - accuracy: 0.9362 - val_loss: 0.2172 - val_accuracy: 0.9361\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.2225 - accuracy: 0.9350 - val_loss: 0.2204 - val_accuracy: 0.9345\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 1s 14ms/step - loss: 0.1928 - accuracy: 0.9471 - val_loss: 0.2161 - val_accuracy: 0.9366\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 19ms/step - loss: 0.2216 - accuracy: 0.9353 - val_loss: 0.2233 - val_accuracy: 0.9359\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 1s 13ms/step - loss: 0.1906 - accuracy: 0.9476 - val_loss: 0.2243 - val_accuracy: 0.9352\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.2463 - accuracy: 0.9336 - val_loss: 0.2254 - val_accuracy: 0.9353\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.2132 - accuracy: 0.9401 - val_loss: 0.2247 - val_accuracy: 0.9350\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.1991 - accuracy: 0.9398 - val_loss: 0.2254 - val_accuracy: 0.9355\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 13ms/step - loss: 0.1729 - accuracy: 0.9478 - val_loss: 0.2404 - val_accuracy: 0.9307\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.2081 - accuracy: 0.9398 - val_loss: 0.2171 - val_accuracy: 0.9386\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 1s 13ms/step - loss: 0.1793 - accuracy: 0.9495 - val_loss: 0.2242 - val_accuracy: 0.9353\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.2259 - accuracy: 0.9357 - val_loss: 0.2257 - val_accuracy: 0.9353\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 0.1989 - accuracy: 0.9468 - val_loss: 0.2202 - val_accuracy: 0.9356\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.2289 - accuracy: 0.9357 - val_loss: 0.2211 - val_accuracy: 0.9388\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.2010 - accuracy: 0.9418 - val_loss: 0.2149 - val_accuracy: 0.9389\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.2222 - accuracy: 0.9426 - val_loss: 0.2415 - val_accuracy: 0.9276\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.1971 - accuracy: 0.9501 - val_loss: 0.2342 - val_accuracy: 0.9294\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2210 - accuracy: 0.9375 - val_loss: 0.2191 - val_accuracy: 0.9376\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1907 - accuracy: 0.9447 - val_loss: 0.2278 - val_accuracy: 0.9330\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.2360 - accuracy: 0.9318 - val_loss: 0.2303 - val_accuracy: 0.9358\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.2040 - accuracy: 0.9400 - val_loss: 0.2286 - val_accuracy: 0.9376\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.2504 - accuracy: 0.9247 - val_loss: 0.2127 - val_accuracy: 0.9373\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2154 - accuracy: 0.9384 - val_loss: 0.2097 - val_accuracy: 0.9406\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2176 - accuracy: 0.9363 - val_loss: 0.2184 - val_accuracy: 0.9368\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1892 - accuracy: 0.9465 - val_loss: 0.2265 - val_accuracy: 0.9331\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 2s 13ms/step - loss: 0.2351 - accuracy: 0.9293 - val_loss: 0.2104 - val_accuracy: 0.9398\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.2034 - accuracy: 0.9409 - val_loss: 0.2078 - val_accuracy: 0.9398\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.2361 - accuracy: 0.9328 - val_loss: 0.2339 - val_accuracy: 0.9309\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.2057 - accuracy: 0.9406 - val_loss: 0.2110 - val_accuracy: 0.9375\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.2266 - accuracy: 0.9340 - val_loss: 0.2155 - val_accuracy: 0.9362\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 15ms/step - loss: 0.1991 - accuracy: 0.9429 - val_loss: 0.2173 - val_accuracy: 0.9349\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 14ms/step - loss: 0.2370 - accuracy: 0.9334 - val_loss: 0.2281 - val_accuracy: 0.9320\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.2085 - accuracy: 0.9423 - val_loss: 0.2073 - val_accuracy: 0.9397\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.2290 - accuracy: 0.9337 - val_loss: 0.2298 - val_accuracy: 0.9347\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.2010 - accuracy: 0.9447 - val_loss: 0.2190 - val_accuracy: 0.9383\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.2194 - accuracy: 0.9360 - val_loss: 0.2152 - val_accuracy: 0.9384\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.1924 - accuracy: 0.9449 - val_loss: 0.2146 - val_accuracy: 0.9376\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 20ms/step - loss: 0.2663 - accuracy: 0.9215 - val_loss: 0.2264 - val_accuracy: 0.9351\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.2312 - accuracy: 0.9342 - val_loss: 0.2177 - val_accuracy: 0.9385\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 2s 13ms/step - loss: 0.2184 - accuracy: 0.9386 - val_loss: 0.2234 - val_accuracy: 0.9349\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 14ms/step - loss: 0.1902 - accuracy: 0.9466 - val_loss: 0.2188 - val_accuracy: 0.9392\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 18ms/step - loss: 0.2215 - accuracy: 0.9367 - val_loss: 0.2230 - val_accuracy: 0.9360\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.1881 - accuracy: 0.9497 - val_loss: 0.2196 - val_accuracy: 0.9352\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 3s 21ms/step - loss: 0.2164 - accuracy: 0.9369 - val_loss: 0.2316 - val_accuracy: 0.9321\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 2s 19ms/step - loss: 0.1885 - accuracy: 0.9482 - val_loss: 0.2110 - val_accuracy: 0.9404\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.2368 - accuracy: 0.9281 - val_loss: 0.2188 - val_accuracy: 0.9358\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.2072 - accuracy: 0.9424 - val_loss: 0.2162 - val_accuracy: 0.9361\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 18ms/step - loss: 0.2041 - accuracy: 0.9415 - val_loss: 0.2155 - val_accuracy: 0.9375\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 13ms/step - loss: 0.1767 - accuracy: 0.9520 - val_loss: 0.2162 - val_accuracy: 0.9355\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.2469 - accuracy: 0.9320 - val_loss: 0.2152 - val_accuracy: 0.9371\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.2148 - accuracy: 0.9379 - val_loss: 0.2061 - val_accuracy: 0.9404\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2267 - accuracy: 0.9323 - val_loss: 0.2179 - val_accuracy: 0.9366\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.1968 - accuracy: 0.9421 - val_loss: 0.2124 - val_accuracy: 0.9389\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.2475 - accuracy: 0.9284 - val_loss: 0.2163 - val_accuracy: 0.9381\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.2110 - accuracy: 0.9388 - val_loss: 0.2032 - val_accuracy: 0.9409\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2270 - accuracy: 0.9364 - val_loss: 0.2155 - val_accuracy: 0.9405\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.2029 - accuracy: 0.9420 - val_loss: 0.2180 - val_accuracy: 0.9395\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.2199 - accuracy: 0.9361 - val_loss: 0.2143 - val_accuracy: 0.9393\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1906 - accuracy: 0.9460 - val_loss: 0.2160 - val_accuracy: 0.9359\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2001 - accuracy: 0.9438\n",
            "-----6---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.2238 - accuracy: 0.9332 - val_loss: 0.2053 - val_accuracy: 0.9406\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.1983 - accuracy: 0.9395 - val_loss: 0.2004 - val_accuracy: 0.9420\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 21ms/step - loss: 0.2067 - accuracy: 0.9388 - val_loss: 0.2107 - val_accuracy: 0.9395\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.1757 - accuracy: 0.9477 - val_loss: 0.2041 - val_accuracy: 0.9413\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 18ms/step - loss: 0.2026 - accuracy: 0.9401 - val_loss: 0.2046 - val_accuracy: 0.9427\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.1781 - accuracy: 0.9496 - val_loss: 0.2049 - val_accuracy: 0.9419\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.2290 - accuracy: 0.9385 - val_loss: 0.2013 - val_accuracy: 0.9430\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.1972 - accuracy: 0.9460 - val_loss: 0.2034 - val_accuracy: 0.9423\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.1813 - accuracy: 0.9457 - val_loss: 0.2111 - val_accuracy: 0.9402\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1543 - accuracy: 0.9561 - val_loss: 0.2120 - val_accuracy: 0.9402\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 19ms/step - loss: 0.1911 - accuracy: 0.9444 - val_loss: 0.2128 - val_accuracy: 0.9388\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.1647 - accuracy: 0.9537 - val_loss: 0.2036 - val_accuracy: 0.9432\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 2s 13ms/step - loss: 0.2111 - accuracy: 0.9407 - val_loss: 0.2107 - val_accuracy: 0.9382\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 0.1859 - accuracy: 0.9482 - val_loss: 0.2001 - val_accuracy: 0.9426\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.2126 - accuracy: 0.9394 - val_loss: 0.2155 - val_accuracy: 0.9381\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.1850 - accuracy: 0.9470 - val_loss: 0.1965 - val_accuracy: 0.9456\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.2076 - accuracy: 0.9435 - val_loss: 0.2030 - val_accuracy: 0.9408\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.1827 - accuracy: 0.9519 - val_loss: 0.2012 - val_accuracy: 0.9433\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2035 - accuracy: 0.9392 - val_loss: 0.2158 - val_accuracy: 0.9364\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1783 - accuracy: 0.9497 - val_loss: 0.2036 - val_accuracy: 0.9402\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.2206 - accuracy: 0.9354 - val_loss: 0.2133 - val_accuracy: 0.9390\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1915 - accuracy: 0.9446 - val_loss: 0.2113 - val_accuracy: 0.9397\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2338 - accuracy: 0.9304 - val_loss: 0.2082 - val_accuracy: 0.9377\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.2008 - accuracy: 0.9439 - val_loss: 0.1914 - val_accuracy: 0.9451\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2007 - accuracy: 0.9411 - val_loss: 0.2018 - val_accuracy: 0.9413\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.1722 - accuracy: 0.9496 - val_loss: 0.2029 - val_accuracy: 0.9421\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.2147 - accuracy: 0.9376 - val_loss: 0.2055 - val_accuracy: 0.9407\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.1894 - accuracy: 0.9453 - val_loss: 0.1958 - val_accuracy: 0.9429\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 17ms/step - loss: 0.2140 - accuracy: 0.9386 - val_loss: 0.2033 - val_accuracy: 0.9408\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.1875 - accuracy: 0.9449 - val_loss: 0.1997 - val_accuracy: 0.9409\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.2084 - accuracy: 0.9422 - val_loss: 0.1997 - val_accuracy: 0.9417\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1802 - accuracy: 0.9486 - val_loss: 0.1993 - val_accuracy: 0.9405\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 15ms/step - loss: 0.2183 - accuracy: 0.9393 - val_loss: 0.2035 - val_accuracy: 0.9407\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 11ms/step - loss: 0.1886 - accuracy: 0.9474 - val_loss: 0.1972 - val_accuracy: 0.9418\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.2115 - accuracy: 0.9409 - val_loss: 0.2087 - val_accuracy: 0.9399\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.1896 - accuracy: 0.9444 - val_loss: 0.2049 - val_accuracy: 0.9416\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.2031 - accuracy: 0.9416 - val_loss: 0.2024 - val_accuracy: 0.9417\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.1789 - accuracy: 0.9507 - val_loss: 0.2017 - val_accuracy: 0.9405\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 20ms/step - loss: 0.2493 - accuracy: 0.9258 - val_loss: 0.2046 - val_accuracy: 0.9425\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.2116 - accuracy: 0.9395 - val_loss: 0.2001 - val_accuracy: 0.9443\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.2040 - accuracy: 0.9425 - val_loss: 0.2115 - val_accuracy: 0.9383\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 15ms/step - loss: 0.1744 - accuracy: 0.9516 - val_loss: 0.1986 - val_accuracy: 0.9435\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 19ms/step - loss: 0.2041 - accuracy: 0.9444 - val_loss: 0.2146 - val_accuracy: 0.9347\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.1797 - accuracy: 0.9535 - val_loss: 0.2080 - val_accuracy: 0.9388\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.1978 - accuracy: 0.9422 - val_loss: 0.2011 - val_accuracy: 0.9444\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 15ms/step - loss: 0.1685 - accuracy: 0.9545 - val_loss: 0.2036 - val_accuracy: 0.9411\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 19ms/step - loss: 0.2141 - accuracy: 0.9379 - val_loss: 0.2051 - val_accuracy: 0.9404\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.1886 - accuracy: 0.9448 - val_loss: 0.2006 - val_accuracy: 0.9409\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 14ms/step - loss: 0.1877 - accuracy: 0.9471 - val_loss: 0.2066 - val_accuracy: 0.9397\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.1615 - accuracy: 0.9563 - val_loss: 0.2000 - val_accuracy: 0.9406\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 14ms/step - loss: 0.2289 - accuracy: 0.9334 - val_loss: 0.2028 - val_accuracy: 0.9419\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.1978 - accuracy: 0.9461 - val_loss: 0.1976 - val_accuracy: 0.9407\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.2104 - accuracy: 0.9377 - val_loss: 0.2013 - val_accuracy: 0.9419\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 12ms/step - loss: 0.1834 - accuracy: 0.9471 - val_loss: 0.1927 - val_accuracy: 0.9457\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 15ms/step - loss: 0.2279 - accuracy: 0.9336 - val_loss: 0.2041 - val_accuracy: 0.9413\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 0.1951 - accuracy: 0.9473 - val_loss: 0.2001 - val_accuracy: 0.9416\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 11ms/step - loss: 0.2131 - accuracy: 0.9383 - val_loss: 0.2020 - val_accuracy: 0.9425\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.1861 - accuracy: 0.9474 - val_loss: 0.2018 - val_accuracy: 0.9436\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.1998 - accuracy: 0.9416 - val_loss: 0.1992 - val_accuracy: 0.9419\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1777 - accuracy: 0.9492 - val_loss: 0.1967 - val_accuracy: 0.9440\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.9474\n",
            "-----7---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 15ms/step - loss: 0.2066 - accuracy: 0.9383 - val_loss: 0.1889 - val_accuracy: 0.9465\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.1843 - accuracy: 0.9470 - val_loss: 0.1951 - val_accuracy: 0.9434\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.1904 - accuracy: 0.9439 - val_loss: 0.1954 - val_accuracy: 0.9425\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.1646 - accuracy: 0.9522 - val_loss: 0.1896 - val_accuracy: 0.9452\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 19ms/step - loss: 0.1891 - accuracy: 0.9423 - val_loss: 0.1917 - val_accuracy: 0.9451\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.1633 - accuracy: 0.9524 - val_loss: 0.1943 - val_accuracy: 0.9432\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.2124 - accuracy: 0.9411 - val_loss: 0.1935 - val_accuracy: 0.9447\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9499 - val_loss: 0.1903 - val_accuracy: 0.9447\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.1671 - accuracy: 0.9499 - val_loss: 0.1973 - val_accuracy: 0.9436\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1419 - accuracy: 0.9569 - val_loss: 0.2027 - val_accuracy: 0.9431\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.1775 - accuracy: 0.9465 - val_loss: 0.1913 - val_accuracy: 0.9469\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 16ms/step - loss: 0.1505 - accuracy: 0.9585 - val_loss: 0.1879 - val_accuracy: 0.9475\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.1953 - accuracy: 0.9427 - val_loss: 0.1931 - val_accuracy: 0.9455\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 15ms/step - loss: 0.1686 - accuracy: 0.9541 - val_loss: 0.1951 - val_accuracy: 0.9445\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 2s 12ms/step - loss: 0.1960 - accuracy: 0.9433 - val_loss: 0.1914 - val_accuracy: 0.9457\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 13ms/step - loss: 0.1709 - accuracy: 0.9515 - val_loss: 0.1875 - val_accuracy: 0.9463\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.1923 - accuracy: 0.9468 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.1658 - accuracy: 0.9575 - val_loss: 0.2055 - val_accuracy: 0.9399\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.1905 - accuracy: 0.9414 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1647 - accuracy: 0.9527 - val_loss: 0.1931 - val_accuracy: 0.9443\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 3s 21ms/step - loss: 0.2027 - accuracy: 0.9400 - val_loss: 0.1969 - val_accuracy: 0.9446\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.1763 - accuracy: 0.9482 - val_loss: 0.2077 - val_accuracy: 0.9414\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.2113 - accuracy: 0.9378 - val_loss: 0.1797 - val_accuracy: 0.9475\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.1821 - accuracy: 0.9470 - val_loss: 0.1870 - val_accuracy: 0.9472\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.1887 - accuracy: 0.9424 - val_loss: 0.1936 - val_accuracy: 0.9449\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1638 - accuracy: 0.9513 - val_loss: 0.1878 - val_accuracy: 0.9469\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 17ms/step - loss: 0.1996 - accuracy: 0.9390 - val_loss: 0.1909 - val_accuracy: 0.9442\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.1723 - accuracy: 0.9503 - val_loss: 0.1834 - val_accuracy: 0.9457\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 0.1979 - accuracy: 0.9444 - val_loss: 0.1943 - val_accuracy: 0.9429\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.1716 - accuracy: 0.9525 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.1909 - accuracy: 0.9464 - val_loss: 0.1930 - val_accuracy: 0.9438\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1614 - accuracy: 0.9518 - val_loss: 0.1986 - val_accuracy: 0.9421\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 2s 12ms/step - loss: 0.2003 - accuracy: 0.9435 - val_loss: 0.1989 - val_accuracy: 0.9430\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.1745 - accuracy: 0.9503 - val_loss: 0.1835 - val_accuracy: 0.9453\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.1975 - accuracy: 0.9407 - val_loss: 0.1935 - val_accuracy: 0.9451\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.1735 - accuracy: 0.9533 - val_loss: 0.1967 - val_accuracy: 0.9428\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 16ms/step - loss: 0.1883 - accuracy: 0.9470 - val_loss: 0.1883 - val_accuracy: 0.9466\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 12ms/step - loss: 0.1643 - accuracy: 0.9545 - val_loss: 0.1835 - val_accuracy: 0.9476\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 2s 20ms/step - loss: 0.2303 - accuracy: 0.9311 - val_loss: 0.1939 - val_accuracy: 0.9444\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.1939 - accuracy: 0.9430 - val_loss: 0.2005 - val_accuracy: 0.9426\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.1903 - accuracy: 0.9447 - val_loss: 0.1935 - val_accuracy: 0.9429\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 11ms/step - loss: 0.1630 - accuracy: 0.9523 - val_loss: 0.1955 - val_accuracy: 0.9454\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 19ms/step - loss: 0.1919 - accuracy: 0.9452 - val_loss: 0.1943 - val_accuracy: 0.9439\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 1s 13ms/step - loss: 0.1666 - accuracy: 0.9557 - val_loss: 0.1950 - val_accuracy: 0.9432\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 17ms/step - loss: 0.1822 - accuracy: 0.9452 - val_loss: 0.1949 - val_accuracy: 0.9457\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 15ms/step - loss: 0.1562 - accuracy: 0.9558 - val_loss: 0.1924 - val_accuracy: 0.9449\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 19ms/step - loss: 0.1974 - accuracy: 0.9415 - val_loss: 0.1964 - val_accuracy: 0.9434\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1697 - accuracy: 0.9537 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 18ms/step - loss: 0.1712 - accuracy: 0.9525 - val_loss: 0.1971 - val_accuracy: 0.9410\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 12ms/step - loss: 0.1472 - accuracy: 0.9563 - val_loss: 0.1915 - val_accuracy: 0.9423\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 15ms/step - loss: 0.2129 - accuracy: 0.9387 - val_loss: 0.1884 - val_accuracy: 0.9454\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 13ms/step - loss: 0.1862 - accuracy: 0.9467 - val_loss: 0.1805 - val_accuracy: 0.9475\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 4s 17ms/step - loss: 0.1933 - accuracy: 0.9440 - val_loss: 0.1997 - val_accuracy: 0.9431\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 13ms/step - loss: 0.1693 - accuracy: 0.9501 - val_loss: 0.1914 - val_accuracy: 0.9443\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 14ms/step - loss: 0.2111 - accuracy: 0.9375 - val_loss: 0.1945 - val_accuracy: 0.9428\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.1812 - accuracy: 0.9473 - val_loss: 0.1825 - val_accuracy: 0.9485\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.1971 - accuracy: 0.9430 - val_loss: 0.1918 - val_accuracy: 0.9460\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 13ms/step - loss: 0.1720 - accuracy: 0.9518 - val_loss: 0.1922 - val_accuracy: 0.9471\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 16ms/step - loss: 0.1847 - accuracy: 0.9456 - val_loss: 0.1878 - val_accuracy: 0.9457\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 11ms/step - loss: 0.1611 - accuracy: 0.9530 - val_loss: 0.1817 - val_accuracy: 0.9474\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9505\n",
            "-----8---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 3s 16ms/step - loss: 0.1962 - accuracy: 0.9416 - val_loss: 0.1819 - val_accuracy: 0.9466\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.1726 - accuracy: 0.9499 - val_loss: 0.1774 - val_accuracy: 0.9494\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 3s 21ms/step - loss: 0.1815 - accuracy: 0.9452 - val_loss: 0.1782 - val_accuracy: 0.9492\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.1526 - accuracy: 0.9560 - val_loss: 0.1830 - val_accuracy: 0.9467\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 19ms/step - loss: 0.1782 - accuracy: 0.9476 - val_loss: 0.1825 - val_accuracy: 0.9476\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.1502 - accuracy: 0.9594 - val_loss: 0.1861 - val_accuracy: 0.9452\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.1971 - accuracy: 0.9473 - val_loss: 0.1833 - val_accuracy: 0.9468\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.1683 - accuracy: 0.9568 - val_loss: 0.1868 - val_accuracy: 0.9467\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.1556 - accuracy: 0.9549 - val_loss: 0.1853 - val_accuracy: 0.9475\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.1306 - accuracy: 0.9617 - val_loss: 0.1815 - val_accuracy: 0.9498\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 19ms/step - loss: 0.1654 - accuracy: 0.9527 - val_loss: 0.1775 - val_accuracy: 0.9495\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.1393 - accuracy: 0.9607 - val_loss: 0.1812 - val_accuracy: 0.9481\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 2s 14ms/step - loss: 0.1828 - accuracy: 0.9461 - val_loss: 0.1959 - val_accuracy: 0.9429\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 12ms/step - loss: 0.1570 - accuracy: 0.9582 - val_loss: 0.1770 - val_accuracy: 0.9511\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.1845 - accuracy: 0.9444 - val_loss: 0.1874 - val_accuracy: 0.9464\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.1603 - accuracy: 0.9563 - val_loss: 0.1773 - val_accuracy: 0.9494\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.1784 - accuracy: 0.9498 - val_loss: 0.1888 - val_accuracy: 0.9437\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.1545 - accuracy: 0.9581 - val_loss: 0.1821 - val_accuracy: 0.9465\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.1782 - accuracy: 0.9480 - val_loss: 0.1765 - val_accuracy: 0.9499\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1511 - accuracy: 0.9565 - val_loss: 0.1758 - val_accuracy: 0.9477\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 3s 21ms/step - loss: 0.1879 - accuracy: 0.9475 - val_loss: 0.1837 - val_accuracy: 0.9493\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.1622 - accuracy: 0.9557 - val_loss: 0.1899 - val_accuracy: 0.9471\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.1977 - accuracy: 0.9406 - val_loss: 0.1727 - val_accuracy: 0.9508\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1681 - accuracy: 0.9528 - val_loss: 0.1689 - val_accuracy: 0.9505\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 18ms/step - loss: 0.1754 - accuracy: 0.9467 - val_loss: 0.1736 - val_accuracy: 0.9490\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1494 - accuracy: 0.9544 - val_loss: 0.1776 - val_accuracy: 0.9477\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 17ms/step - loss: 0.1841 - accuracy: 0.9455 - val_loss: 0.1774 - val_accuracy: 0.9493\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.1623 - accuracy: 0.9538 - val_loss: 0.1756 - val_accuracy: 0.9482\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 18ms/step - loss: 0.1830 - accuracy: 0.9464 - val_loss: 0.1787 - val_accuracy: 0.9490\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 13ms/step - loss: 0.1571 - accuracy: 0.9553 - val_loss: 0.1738 - val_accuracy: 0.9489\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 3s 17ms/step - loss: 0.1767 - accuracy: 0.9508 - val_loss: 0.1817 - val_accuracy: 0.9465\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1495 - accuracy: 0.9553 - val_loss: 0.1768 - val_accuracy: 0.9474\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 15ms/step - loss: 0.1873 - accuracy: 0.9463 - val_loss: 0.1833 - val_accuracy: 0.9472\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 11ms/step - loss: 0.1633 - accuracy: 0.9541 - val_loss: 0.1755 - val_accuracy: 0.9474\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.1869 - accuracy: 0.9472 - val_loss: 0.1949 - val_accuracy: 0.9419\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.1631 - accuracy: 0.9547 - val_loss: 0.1796 - val_accuracy: 0.9473\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 17ms/step - loss: 0.1774 - accuracy: 0.9496 - val_loss: 0.1800 - val_accuracy: 0.9492\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.1535 - accuracy: 0.9570 - val_loss: 0.1754 - val_accuracy: 0.9498\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 20ms/step - loss: 0.2131 - accuracy: 0.9352 - val_loss: 0.1830 - val_accuracy: 0.9488\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 18ms/step - loss: 0.1795 - accuracy: 0.9495 - val_loss: 0.1834 - val_accuracy: 0.9478\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.1755 - accuracy: 0.9495 - val_loss: 0.1846 - val_accuracy: 0.9464\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 12ms/step - loss: 0.1541 - accuracy: 0.9545 - val_loss: 0.1785 - val_accuracy: 0.9486\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.1771 - accuracy: 0.9530 - val_loss: 0.1765 - val_accuracy: 0.9495\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 13ms/step - loss: 0.1511 - accuracy: 0.9602 - val_loss: 0.1798 - val_accuracy: 0.9473\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 17ms/step - loss: 0.1688 - accuracy: 0.9488 - val_loss: 0.1812 - val_accuracy: 0.9480\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 15ms/step - loss: 0.1475 - accuracy: 0.9565 - val_loss: 0.1746 - val_accuracy: 0.9503\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.1806 - accuracy: 0.9507 - val_loss: 0.1853 - val_accuracy: 0.9458\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1560 - accuracy: 0.9552 - val_loss: 0.1824 - val_accuracy: 0.9466\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.1622 - accuracy: 0.9512 - val_loss: 0.1761 - val_accuracy: 0.9486\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.1352 - accuracy: 0.9607 - val_loss: 0.1806 - val_accuracy: 0.9461\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 3s 15ms/step - loss: 0.1997 - accuracy: 0.9440 - val_loss: 0.1827 - val_accuracy: 0.9466\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 11ms/step - loss: 0.1718 - accuracy: 0.9496 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.1820 - accuracy: 0.9491 - val_loss: 0.1888 - val_accuracy: 0.9448\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 10ms/step - loss: 0.1591 - accuracy: 0.9552 - val_loss: 0.1731 - val_accuracy: 0.9506\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 15ms/step - loss: 0.1941 - accuracy: 0.9429 - val_loss: 0.1790 - val_accuracy: 0.9487\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 0.1633 - accuracy: 0.9517 - val_loss: 0.1764 - val_accuracy: 0.9496\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 13ms/step - loss: 0.1861 - accuracy: 0.9461 - val_loss: 0.1753 - val_accuracy: 0.9515\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.1583 - accuracy: 0.9569 - val_loss: 0.1762 - val_accuracy: 0.9504\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 15ms/step - loss: 0.1708 - accuracy: 0.9494 - val_loss: 0.1816 - val_accuracy: 0.9463\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1500 - accuracy: 0.9559 - val_loss: 0.1764 - val_accuracy: 0.9493\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9536\n",
            "-----9---------\n",
            "Epoch 1/2\n",
            "150/150 [==============================] - 2s 13ms/step - loss: 0.1857 - accuracy: 0.9464 - val_loss: 0.1719 - val_accuracy: 0.9497\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 2s 15ms/step - loss: 0.1582 - accuracy: 0.9543 - val_loss: 0.1653 - val_accuracy: 0.9532\n",
            "Epoch 1/2\n",
            "99/99 [==============================] - 2s 21ms/step - loss: 0.1671 - accuracy: 0.9503 - val_loss: 0.1674 - val_accuracy: 0.9517\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.1417 - accuracy: 0.9614 - val_loss: 0.1666 - val_accuracy: 0.9530\n",
            "Epoch 1/2\n",
            "112/112 [==============================] - 3s 19ms/step - loss: 0.1662 - accuracy: 0.9549 - val_loss: 0.1683 - val_accuracy: 0.9512\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2s 17ms/step - loss: 0.1427 - accuracy: 0.9600 - val_loss: 0.1794 - val_accuracy: 0.9492\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 21ms/step - loss: 0.1853 - accuracy: 0.9480 - val_loss: 0.1839 - val_accuracy: 0.9477\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 1s 15ms/step - loss: 0.1562 - accuracy: 0.9604 - val_loss: 0.1740 - val_accuracy: 0.9502\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.1450 - accuracy: 0.9555 - val_loss: 0.1730 - val_accuracy: 0.9507\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 0.1206 - accuracy: 0.9643 - val_loss: 0.1763 - val_accuracy: 0.9500\n",
            "Epoch 1/2\n",
            "117/117 [==============================] - 3s 18ms/step - loss: 0.1527 - accuracy: 0.9537 - val_loss: 0.1742 - val_accuracy: 0.9490\n",
            "Epoch 2/2\n",
            "117/117 [==============================] - 2s 17ms/step - loss: 0.1291 - accuracy: 0.9623 - val_loss: 0.1741 - val_accuracy: 0.9507\n",
            "Epoch 1/2\n",
            "138/138 [==============================] - 3s 16ms/step - loss: 0.1701 - accuracy: 0.9511 - val_loss: 0.1727 - val_accuracy: 0.9520\n",
            "Epoch 2/2\n",
            "138/138 [==============================] - 2s 15ms/step - loss: 0.1465 - accuracy: 0.9600 - val_loss: 0.1696 - val_accuracy: 0.9517\n",
            "Epoch 1/2\n",
            "169/169 [==============================] - 3s 14ms/step - loss: 0.1751 - accuracy: 0.9516 - val_loss: 0.1732 - val_accuracy: 0.9520\n",
            "Epoch 2/2\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 0.1474 - accuracy: 0.9594 - val_loss: 0.1723 - val_accuracy: 0.9510\n",
            "Epoch 1/2\n",
            "105/105 [==============================] - 3s 20ms/step - loss: 0.1693 - accuracy: 0.9516 - val_loss: 0.1729 - val_accuracy: 0.9496\n",
            "Epoch 2/2\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.1419 - accuracy: 0.9620 - val_loss: 0.1725 - val_accuracy: 0.9503\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.1638 - accuracy: 0.9521 - val_loss: 0.1724 - val_accuracy: 0.9503\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.1420 - accuracy: 0.9591 - val_loss: 0.1718 - val_accuracy: 0.9486\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 2s 17ms/step - loss: 0.1763 - accuracy: 0.9501 - val_loss: 0.1793 - val_accuracy: 0.9500\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 2s 19ms/step - loss: 0.1476 - accuracy: 0.9613 - val_loss: 0.1731 - val_accuracy: 0.9518\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.1842 - accuracy: 0.9459 - val_loss: 0.1602 - val_accuracy: 0.9547\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1557 - accuracy: 0.9579 - val_loss: 0.1620 - val_accuracy: 0.9551\n",
            "Epoch 1/2\n",
            "170/170 [==============================] - 3s 14ms/step - loss: 0.1625 - accuracy: 0.9518 - val_loss: 0.1768 - val_accuracy: 0.9503\n",
            "Epoch 2/2\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.1395 - accuracy: 0.9600 - val_loss: 0.1662 - val_accuracy: 0.9505\n",
            "Epoch 1/2\n",
            "136/136 [==============================] - 3s 16ms/step - loss: 0.1694 - accuracy: 0.9462 - val_loss: 0.1654 - val_accuracy: 0.9520\n",
            "Epoch 2/2\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 0.1460 - accuracy: 0.9600 - val_loss: 0.1594 - val_accuracy: 0.9535\n",
            "Epoch 1/2\n",
            "124/124 [==============================] - 3s 19ms/step - loss: 0.1709 - accuracy: 0.9505 - val_loss: 0.1661 - val_accuracy: 0.9503\n",
            "Epoch 2/2\n",
            "124/124 [==============================] - 2s 16ms/step - loss: 0.1444 - accuracy: 0.9581 - val_loss: 0.1775 - val_accuracy: 0.9464\n",
            "Epoch 1/2\n",
            "127/127 [==============================] - 2s 14ms/step - loss: 0.1649 - accuracy: 0.9558 - val_loss: 0.1672 - val_accuracy: 0.9515\n",
            "Epoch 2/2\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1371 - accuracy: 0.9629 - val_loss: 0.1682 - val_accuracy: 0.9498\n",
            "Epoch 1/2\n",
            "166/166 [==============================] - 3s 15ms/step - loss: 0.1760 - accuracy: 0.9471 - val_loss: 0.1691 - val_accuracy: 0.9496\n",
            "Epoch 2/2\n",
            "166/166 [==============================] - 2s 13ms/step - loss: 0.1499 - accuracy: 0.9578 - val_loss: 0.1672 - val_accuracy: 0.9507\n",
            "Epoch 1/2\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.1761 - accuracy: 0.9519 - val_loss: 0.1779 - val_accuracy: 0.9479\n",
            "Epoch 2/2\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.1511 - accuracy: 0.9605 - val_loss: 0.1668 - val_accuracy: 0.9515\n",
            "Epoch 1/2\n",
            "134/134 [==============================] - 3s 17ms/step - loss: 0.1693 - accuracy: 0.9512 - val_loss: 0.1698 - val_accuracy: 0.9518\n",
            "Epoch 2/2\n",
            "134/134 [==============================] - 2s 15ms/step - loss: 0.1442 - accuracy: 0.9619 - val_loss: 0.1652 - val_accuracy: 0.9539\n",
            "Epoch 1/2\n",
            "101/101 [==============================] - 3s 21ms/step - loss: 0.1983 - accuracy: 0.9405 - val_loss: 0.1666 - val_accuracy: 0.9531\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 2s 19ms/step - loss: 0.1652 - accuracy: 0.9523 - val_loss: 0.1707 - val_accuracy: 0.9530\n",
            "Epoch 1/2\n",
            "145/145 [==============================] - 3s 16ms/step - loss: 0.1693 - accuracy: 0.9493 - val_loss: 0.1705 - val_accuracy: 0.9506\n",
            "Epoch 2/2\n",
            "145/145 [==============================] - 2s 15ms/step - loss: 0.1416 - accuracy: 0.9605 - val_loss: 0.1693 - val_accuracy: 0.9522\n",
            "Epoch 1/2\n",
            "113/113 [==============================] - 3s 19ms/step - loss: 0.1654 - accuracy: 0.9544 - val_loss: 0.1734 - val_accuracy: 0.9504\n",
            "Epoch 2/2\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.1411 - accuracy: 0.9624 - val_loss: 0.1723 - val_accuracy: 0.9506\n",
            "Epoch 1/2\n",
            "95/95 [==============================] - 2s 21ms/step - loss: 0.1554 - accuracy: 0.9521 - val_loss: 0.1686 - val_accuracy: 0.9519\n",
            "Epoch 2/2\n",
            "95/95 [==============================] - 1s 15ms/step - loss: 0.1346 - accuracy: 0.9605 - val_loss: 0.1666 - val_accuracy: 0.9528\n",
            "Epoch 1/2\n",
            "106/106 [==============================] - 3s 20ms/step - loss: 0.1690 - accuracy: 0.9510 - val_loss: 0.1745 - val_accuracy: 0.9478\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 0.1446 - accuracy: 0.9587 - val_loss: 0.1679 - val_accuracy: 0.9509\n",
            "Epoch 1/2\n",
            "123/123 [==============================] - 3s 18ms/step - loss: 0.1491 - accuracy: 0.9578 - val_loss: 0.1638 - val_accuracy: 0.9529\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.1280 - accuracy: 0.9624 - val_loss: 0.1724 - val_accuracy: 0.9473\n",
            "Epoch 1/2\n",
            "165/165 [==============================] - 2s 12ms/step - loss: 0.1888 - accuracy: 0.9473 - val_loss: 0.1681 - val_accuracy: 0.9524\n",
            "Epoch 2/2\n",
            "165/165 [==============================] - 2s 14ms/step - loss: 0.1596 - accuracy: 0.9560 - val_loss: 0.1576 - val_accuracy: 0.9536\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.1735 - accuracy: 0.9493 - val_loss: 0.1699 - val_accuracy: 0.9512\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 13ms/step - loss: 0.1491 - accuracy: 0.9589 - val_loss: 0.1712 - val_accuracy: 0.9513\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 3s 15ms/step - loss: 0.1834 - accuracy: 0.9463 - val_loss: 0.1653 - val_accuracy: 0.9536\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 14ms/step - loss: 0.1539 - accuracy: 0.9581 - val_loss: 0.1671 - val_accuracy: 0.9536\n",
            "Epoch 1/2\n",
            "185/185 [==============================] - 3s 14ms/step - loss: 0.1735 - accuracy: 0.9498 - val_loss: 0.1732 - val_accuracy: 0.9507\n",
            "Epoch 2/2\n",
            "185/185 [==============================] - 2s 13ms/step - loss: 0.1505 - accuracy: 0.9600 - val_loss: 0.1684 - val_accuracy: 0.9525\n",
            "Epoch 1/2\n",
            "149/149 [==============================] - 3s 16ms/step - loss: 0.1592 - accuracy: 0.9534 - val_loss: 0.1708 - val_accuracy: 0.9501\n",
            "Epoch 2/2\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1371 - accuracy: 0.9608 - val_loss: 0.1680 - val_accuracy: 0.9507\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1540 - accuracy: 0.9557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "GNc8SzlO8eoB",
        "outputId": "de4ea06b-d4f4-4eeb-c151-ee17464b6753"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot(serverhist1['accuracy'], label=\"Genetic CFL\", color=\"#061080\", marker = \"^\")\n",
        "ax.plot(serverhist['accuracy'], label=\"FL\", color=\"#068006\", marker=\".\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "ax.set_xlabel(\"Rounds\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot(serverhist1['loss'], label=\"Genetic CFL\", color=\"#061080\", marker=\"^\")\n",
        "ax.plot(serverhist['loss'], label=\"FL\", color=\"#068006\", marker=\".\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "ax.set_xlabel(\"Rounds\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Generic FL.pdf\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tTnk1_Q4jLZ-",
        "outputId": "49501002-2f24-46cb-a993-01d1ab076dd9"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"Generic FL.pdf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d159f0af-265f-448a-831a-747c48fe330f\", \"Generic FL.pdf\", 15921)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q569VCEa6IQP"
      },
      "source": [
        "# Normal Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8HDTnmb0F-9"
      },
      "source": [
        "server_model_norm = create_server_model()\n",
        "num=0\n",
        "server_model_norm.compile(optimizer = tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "n_hist=server_model_norm.fit(X_train[6000*num:6000*(num+1)], y_train[6000*num:6000*(num+1)], epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NR4Du5biETR"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax=fig.add_subplot(121)\n",
        "ax.plot(n_hist.history['accuracy'], label=\"accuracy\")\n",
        "ax.plot(n_hist.history['val_accuracy'], label=\"val accuracy\")\n",
        "ax.legend()\n",
        "ax=fig.add_subplot(122)\n",
        "ax.plot(n_hist.history['loss'], label=\"loss\")\n",
        "ax.plot(n_hist.history['val_loss'], label=\"val loss\")\n",
        "ax.legend()\n",
        "plt.savefig(\"Generic\", dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}